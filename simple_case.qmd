
This QMD will house the simple case of CLQI, where we impute missing data from a biomarker through using one study
This method is similar to Predictive Mean Matching (PMM) where we aim to avoid implausible values and reduce bias after imputation. However, PMM performs well from 10%-30% missing data. After that, Complete Case Analyses seem to perform better

```{r}
#necessary libraries
library(tidyverse)
library(ggplot2)
library(quantreg)
library(missMethods)
library(MASS)
library(purrr)
library(tictoc)
library(mice) #for PMM
```

Some important transformation functions

```{r}
#logit and expit functions for myself
logit <- function(prob) {
  value <- log(prob / (1 - prob))
  return(value)
}

expit <- function(x) {
  value <- 1 / (1 + exp(-x))
  return(value)
}

#now some other transformation functions
log_quant_transform <- function(value, min, max) {
  if (is.na(value)) return(NA)  # short-circuit if missing
  if (value <= min | value >= max) return(NA)
  return(log((value - min) / (max - value)))
}

inv_log_quant_transform <- function(value, min, max) {
  new_value <- (exp(value)*max + min) / (1+exp(value))
  return(new_value)
}
```

The Data Generating Mechanism: just one study with a very simple mechanism

```{r}
data_generation <- function(sample_size, missing_prop, 
                            b_0 = logit(0.3), b_1 = log(1.6), b_2 = log(0.7)) {

  #generate my data
  B <- rbinom(sample_size, size = 1, prob = 0.4)
  X <- rchisq(sample_size, df = 5 + 3*B) #if B = 1, X ~ chisq(8)
  Y <- plogis(b_0 + b_1*X + b_2*B) #we have some effects
  Y_bin <- rbinom(sample_size, size = 1, prob = Y)
  
  
  my_data <- data.frame(
      confounder = B,
      biomarker = X,
      missing_biomarker = X,
      outcome = Y_bin
    )
  
  my_data <- delete_MCAR(my_data, missing_prop, "missing_biomarker") #make missing_prop percent of data missing MCAR
  
  #now we create the transformed variable... sapply is NOT working
  my_data$transformed_biomarker <- NA
  
  for(i in 1:nrow(my_data)) {
    if(is.na(my_data$missing_biomarker[i])) {
      my_data$transformed_biomarker[i] <- NA} 
    else {
      my_data$transformed_biomarker[i] <- log_quant_transform(my_data$missing_biomarker[i], 
                                                              min = 0, max = max(my_data$missing_biomarker, na.rm = TRUE))}
  }
  
  return(my_data)
}
```

some plots of my data, credit to ChatGPT for making this process quicker

```{r}
created_data <- data_generation(sample_size = 2000, missing_prop = 0.5)

#FIRST CHECK: Logistic Regression 
regression_results <- glm(outcome ~ biomarker + confounder,
                          data = created_data,
                          family = "binomial")

summary(regression_results)
log(1.6) #we're good

created_data
```

Second check: Biomarker distributions between the confounder groups

```{r}
# Convert confounder to a factor for better labeling and aesthetics
created_data$confounder <- factor(created_data$confounder, levels = c(0, 1), labels = c("Confounder = 0", "Confounder = 1"))

# Create the plot with overlaid density curves
ggplot(data = created_data, aes(x = biomarker, fill = confounder, color = confounder)) +
  geom_density(alpha = 0.5) + 
  labs(
    title = "Biomarker Distribution by Confounder",
    x = "Biomarker",
    y = "Density"
  ) +
  scale_fill_manual(values = c("skyblue", "orange")) +  # Custom colors for filling
  scale_color_manual(values = c("blue", "red"))        # Custom border colors
```

# PMM: some issues right now, will come back to this later

```{r, eval=FALSE}
created_data_for_PMM <- data_generation(sample_size = 2000, missing_prop = 0.4) |>
  dplyr::select(confounder, missing_biomarker, outcome)

#a little test
imp <- mice(created_data_for_PMM, 
            method = "pmm", 
            m = 10, seed = 500)

#larger (but still small) test
num_imp <- 10
PMM_coefficients <- c()

for(i in 1:num_imp) {
  imputed_data <- complete(imp, action = i)
  my_reg <- glm(outcome ~ missing_biomarker + confounder,
                data = imputed_data,
                family = "binomial")
  
  PMM_coefficients[i] <- summary(my_reg)$coefficients[2]
}

PMM_coefficients
mean(PMM_coefficients) - log(1.6) #we're doing pretty good 
```

# CLQI

Perform the algorithm: generate my regression coefficients and bam

```{r}
coefficient_data <- data.frame()

suppressWarnings({
  for(i in seq(from = 0.01, to = 0.99, by = 0.01)) {
      reg_coeff <- rq(transformed_biomarker ~ outcome + confounder, 
                      data = created_data, 
                      tau=i)
      
      #create the data frame 
      new_data <- data.frame(
        b_0 = reg_coeff$coefficients[1],
        b_outcome = reg_coeff$coefficients[2],
        b_confounder = reg_coeff$coefficients[3],
        quant = i)
        
      coefficient_data <- rbind(coefficient_data, new_data) #add to new iterations
    }
})

coefficient_data

#here's the function format
coefficient_generator <- function(my_data) {
  suppressWarnings({
    for(i in seq(from = 0.01, to = 0.99, by = 0.01)) {
        reg_coeff <- rq(transformed_biomarker ~ outcome + confounder, 
                        data = my_data, 
                        tau=i)
        
        #create the data frame 
        new_data <- data.frame(
          b_0 = reg_coeff$coefficients[1],
          b_outcome = reg_coeff$coefficients[2],
          b_confounder = reg_coeff$coefficients[3],
          quant = i)
          
        coefficient_data <- rbind(coefficient_data, new_data) #add to new iterations
      }
  })

  return(coefficient_data)
}
  
coefficient_generator(created_data) #should be the same
```

Now we perform the algorithm on the missing data (function from my older document)
First, here's a function that will generate uniform values really quickly
*This function returns transformed versions of the values we want to gather*

```{r}
uniform_values <- function() {
  u <- runif(1, min = 1, max = 99) #aka from 0.01 to 0.99
  
  #all the values we need from the uniform
  floor_u <- floor(u)
  mod_u <- (u - floor(u))
  next_u <- ceiling(u)
  
  #now putting this into a vector
  my_u <- c(u, floor_u, mod_u, next_u)
  return(my_u)
}

imputation_algorithm <- function(my_coefficients, my_data, row_index) {
  
  u_vector <- uniform_values() #get the uniform values and extract necessary information
  floor_quantile <- my_coefficients[u_vector[2], ] #floor
  modulus <- u_vector[3] #modulus
  ceiling_quantile <- my_coefficients[u_vector[4], ] #ceiling
  
  #need to calculate regression values... really messy don't look at this
  lower_quantile_value <- floor_quantile$b_0 +
    (floor_quantile$b_outcome * my_data[row_index,]$outcome) + (floor_quantile$b_confounder * my_data[row_index,]$confounder) 

  upper_quantile_value <- ceiling_quantile$b_0 +
    (ceiling_quantile$b_outcome * my_data[row_index,]$outcome) + (ceiling_quantile$b_confounder * my_data[row_index,]$confounder)

  #now the imputation values!
  imputation_value_transformed <- ((1-modulus)*lower_quantile_value) + (modulus*upper_quantile_value)
  
  return(imputation_value_transformed)
}
```

Now we will perform the CLQI algorithm

```{r}
#here are the data that we need
data_for_imp <- data_generation(sample_size = 10000, missing_prop = 0.8)
max(data_for_imp$biomarker, na.rm=TRUE)


coefficient_data_for_imp <- coefficient_generator(data_for_imp)

for(row_index in 1:nrow(data_for_imp)) {
  if(is.na(data_for_imp$transformed_biomarker[row_index])) {
    imputed_value <- imputation_algorithm(my_coefficients = coefficient_data_for_imp,
                                          my_data = data_for_imp,
                                          row_index = row_index)
    
    data_for_imp$transformed_biomarker[row_index] <- imputed_value
  }
}

data_for_imp
```

Untransform my transformed_biomarker and check with the theoretical distribution between both groups

```{r}
data_for_imp <- data_for_imp |>
  mutate(untransformed_imputed_biomarker = sapply(transformed_biomarker, inv_log_quant_transform, 
                                                  min = 0, max = max(data_for_imp$missing_biomarker, na.rm = TRUE)))

data_for_imp_new <- data_for_imp

data_for_imp_new$confounder <- factor(data_for_imp_new$confounder, levels = c(0, 1), labels = c("Confounder = 0", "Confounder = 1"))

# Create the plot with overlaid density curves
ggplot(data = data_for_imp_new, aes(x = biomarker, fill = confounder, color = confounder)) +
  geom_density(alpha = 0.5) + 
  labs(
    title = "Biomarker Distribution by Confounder",
    x = "Biomarker",
    y = "Density"
  ) +
  scale_fill_manual(values = c("skyblue", "orange")) +  # Custom colors for filling
  scale_color_manual(values = c("blue", "red"))        # Custom border colors


ggplot(data = data_for_imp_new, aes(x = untransformed_imputed_biomarker, fill = confounder, color = confounder)) +
  geom_density(alpha = 0.5) + 
  labs(
    title = "Imputed Biomarker Distribution by Confounder",
    x = "Biomarker",
    y = "Density"
  ) +
  scale_fill_manual(values = c("skyblue", "orange")) +  # Custom colors for filling
  scale_color_manual(values = c("blue", "red")) +       # Custom border colors
  stat_function(fun = dchisq, args = list(df = 5), aes(color = NULL), linetype = "dashed", size = 1, color = "black") +
  stat_function(fun = dchisq, args = list(df = 8), aes(color = NULL), linetype = "dotted", size = 1, color = "darkgreen")

```

```{r}
my_glm <- glm(outcome ~ untransformed_imputed_biomarker + confounder,
              data = data_for_imp,
              family = "binomial")

summary(my_glm)$coefficients[2]
log(1.6)
```

Some extra things: 1-Wasserstein distance and KS test

```{r}
data_for_imp_zero <- data_for_imp |>
  filter(confounder == 0)

data_for_imp_one <- data_for_imp |>
  filter(confounder == 1)

ks.test(data_for_imp_zero$untransformed_imputed_biomarker, "pchisq", df = 5)
ks.test(data_for_imp_one$untransformed_imputed_biomarker, "pchisq", df = 8)
```

```{r}

wasserstein_1_distance <- function(variable, my_df) {
  empirical_cdf <- ecdf(variable)
  u <- seq(0, 0.9999999, length.out = 1000) #we will be working with the quantile version. Integration approximation
  
  #now get the quantiles
  empirical_quantiles <- quantile(variable, probs = u)
  theoretical_quantiles <- qchisq(u, df = my_df)
  
  return(mean(as.numeric(abs(empirical_quantiles - theoretical_quantiles))))
}

wasserstein_1_distance(data_for_imp_zero$untransformed_imputed_biomarker, my_df = 5)
wasserstein_1_distance(data_for_imp_one$untransformed_imputed_biomarker, my_df = 8)
```




##############################################


Now here is the Multiple Imputation aspect of the method... then we will do a simulation study

```{r, eval=FALSE}
values_CLQI <- c()
MI_iter <- 10 
data_for_imp_fresh <- data_generation(sample_size = 10000, missing_prop = 0.8)
coefficient_data_for_imp <- coefficient_generator(data_for_imp_fresh)

for(imp in 1:MI_iter) {
  
  data_for_imp <- data_for_imp_fresh #resets any imputation that happened
  
  for(row_index in 1:nrow(data_for_imp)) {
    if(is.na(data_for_imp$transformed_biomarker[row_index])) {
      imputed_value <- imputation_algorithm(my_coefficients = coefficient_data_for_imp,
                                            my_data = data_for_imp,
                                            row_index = row_index)
      
      data_for_imp$transformed_biomarker[row_index] <- imputed_value
    }
  }
  
  data_for_imp <- data_for_imp |>
  mutate(untransformed_imputed_biomarker = sapply(transformed_biomarker, inv_log_quant_transform, 
                                                  min = 0, max = max(data_for_imp$missing_biomarker, na.rm = TRUE)))

  my_glm <- glm(outcome ~ untransformed_imputed_biomarker + confounder,
              data = data_for_imp,
              family = "binomial")

  values_CLQI[imp] <- summary(my_glm)$coefficients[2]
}

values_CLQI
mean(values_CLQI) - log(1.6) #bias...
```

Just a quick simulation thing, no functions for now :/ (super messy)

```{r}
#rubin's rule for standard error is complicated, so just keep it in a simple function
rubin_rule_SE <- function(values_MI, SE_MI) { #both inputs are vectors
  variance_within_MI <- mean((SE_MI)^2)
  variance_between_MI <- sum((values_MI - mean(values_MI))^2) / (length(values_MI) - 1)
  total_variance <- variance_within_MI + variance_between_MI + (variance_between_MI / length(values_MI))
  
  return(sqrt(total_variance))
}
```

```{r}
coverage <- function(parameter, SE, t_star, true_val) {
  if(parameter - t_star*sqrt(SE) <= true_val & true_val <= parameter + t_star*sqrt(SE)) {
    return(1)
  } else{
    return(0)
  }
}
```



```{r, eval=FALSE}
set.seed(500)
#now 1000 iterations 
estimate_values_CLQI <- c()
coverage_CLQI <- c()
power_CLQI <- c()
estimate_values_PMM <- c()
coverage_PMM <- c()
power_PMM <- c()

#my sample size
my_sample <- 1000

tictoc::tic()
num_sim <- 5000 #5000 simulations cus why not
for(i in 1:num_sim) { #repeated sampling
  #these are our vectors we will be using for each simulation
  values_CLQI <- c()
  SE_CLQI <- c()
  values_PMM <- c()
  SE_PMM <- c()
  
  #number of imputations
  MI_iter <- 10 
  
  #data generation and coefficient generation for CLQI
  data_for_imp_fresh <- data_generation(sample_size = my_sample, missing_prop = 0.3)
  coefficient_data_for_imp <- coefficient_generator(data_for_imp_fresh)
  
#CLQI
  for(imp in 1:MI_iter) { #multiple imputation
    
    data_for_imp <- data_for_imp_fresh #resets any imputation that happened
    
    for(row_index in 1:nrow(data_for_imp)) { #running CLQI algorithm
      if(is.na(data_for_imp$transformed_biomarker[row_index])) {
        imputed_value <- imputation_algorithm(my_coefficients = coefficient_data_for_imp,
                                              my_data = data_for_imp,
                                              row_index = row_index)
        
        data_for_imp$transformed_biomarker[row_index] <- imputed_value
      }
    }
    
    data_for_imp <- data_for_imp |>
    mutate(untransformed_imputed_biomarker = sapply(transformed_biomarker, inv_log_quant_transform, 
                                                    min = 0, max = max(data_for_imp$missing_biomarker, na.rm = TRUE)))
  
    my_glm <- glm(outcome ~ untransformed_imputed_biomarker + confounder,
                data = data_for_imp,
                family = "binomial")
  
    values_CLQI[imp] <- summary(my_glm)$coefficients[2]
    SE_CLQI[imp] <- summary(my_glm)$coefficients[2, 2]
  }
  
  #get the estimate values FOR BIAS
  estimate_values_CLQI[i] <- mean(values_CLQI)
  
  #now FOR COVERAGE
  total_SE_CLQI <- rubin_rule_SE(values_CLQI, SE_CLQI)
  t_star <- qt(0.975, df = my_sample - 1)
  coverage_CLQI[i] <- coverage(parameter = mean(values_CLQI),
                               SE = total_SE_CLQI,
                               t_star = t_star,
                               true_val = log(1.6))
  
  #now for POWER
  power_CLQI[i] <- "not for sale"
  #############################################################################
   
#PMM
suppressMessages({
  suppressWarnings({
    capture.output({
      data_for_imp_PMM <- data_for_imp_fresh |>
        dplyr::select(outcome, missing_biomarker, confounder)
      
      imp <- mice(data_for_imp_PMM, method = "pmm", m = MI_iter)
      
      for (j in 1:MI_iter) {
        imputed_data <- complete(imp, action = j)
        my_reg <- glm(outcome ~ missing_biomarker + confounder,
                      data = imputed_data,
                      family = "binomial")
        
        values_PMM[j] <- summary(my_reg)$coefficients[2]
        SE_PMM[j] <- summary(my_reg)$coefficients[2, 2]
      }
      
      estimate_values_PMM[i] <- mean(values_PMM)
      
      #now FOR COVERAGE
      total_SE_PMM <- rubin_rule_SE(values_PMM, SE_PMM)
      t_star <- qt(0.975, df = my_sample - 1)
      coverage_PMM[i] <- coverage(parameter = mean(values_PMM),
                                   SE = total_SE_PMM,
                                   t_star = t_star,
                                   true_val = log(1.6))

      power_PMM[i] <- "not for sale"
    }, file = NULL) # suppress printed output
  })
})
  
}
tictoc::toc()

#make this into a dataset
simulations <- data.frame(
  estimate_values_CLQI = estimate_values_CLQI,
  coverage_CLQI = coverage_CLQI,
  power_CLQI = power_CLQI,
  estimate_values_PMM = estimate_values_PMM,
  coverage_PMM = coverage_PMM,
  power_PMM = power_PMM
)

#quick bias checks
mean(simulations$estimate_values_CLQI) - log(1.6)
mean(simulations$estimate_values_PMM) - log(1.6)

#save this!
saveRDS(simulations, file="./simulations.rds")
```

Now a check!

```{r}
estimate_values_CLQI <- as.data.frame(readRDS(file="./simulations.rds")) |>
  rename(result = `readRDS(file = "./beta_results.rds")`) |>
  mutate(bias = result - log(1.6))

ggplot(data = estimate_values_CLQI, aes(x = bias)) + 
  geom_density()

mean(estimate_values_CLQI$bias)
mean(coverage_CLQI)
```


*I remember from STAT 495 that there was a cost vs power formula that we can use*

```{r}
# Plot histogram of your biomarker data
hist(created_data$biomarker, probability = TRUE, breaks = 100,
     col = "lightgray", border = "white",
     main = "Empirical Biomarker vs. Theoretical Mixture",
     xlab = "Biomarker")

# Generate a sequence of x-values covering the range of your data
x_vals <- seq(min(created_data$biomarker), 
              quantile(created_data$biomarker, 0.99), 
              length.out = 1000)

# Calculate theoretical mixture density
mixture_density <- 0.6 * dchisq(x_vals, df = 5) + 0.4 * dchisq(x_vals, df = 8)

# Overlay the theoretical density curve
lines(x_vals, mixture_density, col = "red", lwd = 2)

# Add a legend
legend("topright", legend = "Theoretical Mixture: 0.6 * χ²(5) + 0.4 * χ²(8)",
       col = "red", lwd = 2, bty = "n")

```

