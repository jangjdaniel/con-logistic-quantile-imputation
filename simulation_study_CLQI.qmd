
This QMD will house the simulation study for Conditional Logistic Quantile Imputation (CLQI), comparing its performance measures to existing methods in the literature (Complete Case, Predictive Mean Matching - PMM)

CLQI's advantage is similar to PMM where we aim to avoid implausible values and reduce bias after imputation. However, PMM has several limitations, such as only performing well under 10%-30% missing data, relying on assumptions for linear regression, and the distribution for imputation having little to moderate skew only.

# Initial Code: Must run everytime

```{r}
#necessary libraries
library(tidyverse)
library(ggplot2)
library(MASS)
library(purrr) #for looping
library(tictoc) #for checking runtime

library(quantreg) #for logistic quantile regression
library(missMethods) #general missing methods
library(mice) #for PMM

library(Rcpp) #future implementation for faster calculations in CLQI
```

Some important transformation `functions` that we will use for the CLQI algorithm:

```{r}
#logit and expit functions for myself
logit <- function(prob) {
  value <- log(prob / (1 - prob))
  return(value)
}

expit <- function(x) {
  value <- 1 / (1 + exp(-x))
  return(value)
}

#now some other transformation functions
log_quant_transform <- function(value, min, max) {
  if (is.na(value)) return(NA)  # short-circuit if missing
  if (value <= min | value >= max) return(NA)
  return(log((value - min) / (max - value)))
}

inv_log_quant_transform <- function(value, min, max) {
  new_value <- (exp(value)*max + min) / (1+exp(value))
  return(new_value)
}
```

# Data Generating Mechanism (DGM)

For our Data Generating Mechanism, we need a way to obtain quantile values for a mixture distribution with two chi square distributions. The function is specified below with two test cases

```{r}
get_mixture_quantile <- function(p) {
  uniroot(
    function(q) 0.6 * pchisq(q, 5) + 0.4 * pchisq(q, 8) - p, #this is specific to our DGM
    c(0, 1000)
  )$root
}

# Compute each quantile and assign to unique objects
q_9999 <- get_mixture_quantile(0.9999)
q_999999 <- get_mixture_quantile(0.999999)
```

Below is the function for our DGM, with distributions and coefficients specified in `Section 3`. 
The logic of this function is we first generate our data from specificed distributions

Some of the *MAR* functionality is not implemented yet

```{r}
data_generation <- function(sample_size, missing_prop, 
                            p_missing_zero = 0.35, p_missing_one = 0.20,
                            b_0 = logit(0.1), b_1 = log(1.1), b_2 = log(0.7)) {

  #generate my data
  B <- rbinom(sample_size, size = 1, prob = 0.4)
  V <- rnorm(sample_size, mean = 0, sd = 2.5)
  X <- rchisq(sample_size, df = 5 + 3*B) #if B = 1, X ~ chisq(8)
  Y <- plogis(b_0 + b_1*X + b_2*B) #we have some effects
  Y_bin <- rbinom(sample_size, size = 1, prob = Y)
  
  #taking all these elements and putting them into a data frame
  my_data <- data.frame(
      confounder = B,
      predictor = V,
      biomarker = X,
      missing_biomarker = X,
      missing_biomarker_MAR = X,
      outcome = Y_bin
    )

  #make missing_prop percent of data missing MCAR
  my_data <- delete_MCAR(my_data, missing_prop, "missing_biomarker") 
  
#what about the MAR scenario?
  #get probabilities based on confounder and unif from 0 to 1 for all my datapoints
  prob <- ifelse(my_data$confounder == 1, p_missing_one, p_missing_zero)
  u <- runif(nrow(my_data))
  
  #apply MAR missingness
  my_data$missing_biomarker_MAR <- ifelse(u < prob, #if my u value is less than my probability
                                          NA, #make it missing
                                          my_data$missing_biomarker_MAR) #if not, keep the observation

#now we create the transformed variable... sapply is NOT working
  my_data$transformed_biomarker <- NA
  
  for(i in 1:nrow(my_data)) {
    if(is.na(my_data$missing_biomarker[i])) {
      my_data$transformed_biomarker[i] <- NA} 
    else {
      my_data$transformed_biomarker[i] <- log_quant_transform(my_data$missing_biomarker[i], 
                                                              min = 0, max = q_999999)}
  }
  
  return(my_data)
}
```

*We need to ensure that this value is consistent throughout the entire analysis. This is why there are multiple chunks for seemingly small things. We will describe in detail what these are*

We need to use the true effect defined in the DGM throughout the simulation study. 

```{r}
#our true effect
true_effect <- log(1.1)
```

For logistic regression throughout the simulation study, we will use these formulas for specific cases

```{r}
#for CLQI, this quantile logistic relationship is what we need to generate imputed values
imputation_relationships <- "transformed_biomarker ~ outcome + confounder + predictor"

#in general, to check the true logistic regression for the data before missingness, we need this
full_relationships <- "outcome ~ biomarker + confounder + predictor"

#INCONSISTENCY: for PMM and CC, it ends up being missing_biomarker. Not good
missing_relationships <- "outcome ~ untransformed_imputed_biomarker + confounder + predictor"
```

For any test case we have, we will use this data only. This is for consistency

```{r}
#for any tests, you must take from testing_data_only

set.seed(500)
testing_data_only <- data_generation(sample_size = 1000, missing_prop = 0.3)
```

Some plots of generated data as a `check`

```{r, eval=FALSE}
created_data <- testing_data_only

#FIRST CHECK: Logistic Regression 
regression_results <- glm(outcome ~ biomarker + confounder,
                          data = created_data,
                          family = "binomial")

summary(regression_results)$coefficients[2] - true_effect #what is the bias of the biomarker estimate?

# Convert confounder to a factor for better labeling and aesthetics
created_data$confounder <- factor(created_data$confounder, levels = c(0, 1), labels = c("Confounder = 0", "Confounder = 1"))

# Create the plot with overlaid density curves
ggplot(data = created_data, aes(x = biomarker, fill = confounder, color = confounder)) +
  geom_density(alpha = 0.5) + 
  labs(
    title = "Biomarker Distribution by Confounder",
    x = "Biomarker",
    y = "Density"
  ) +
  scale_fill_manual(values = c("skyblue", "orange")) +  # Custom colors for filling
  scale_color_manual(values = c("blue", "red"))        # Custom border colors
```

# Code for methods to be compared (PMM, CLQI)
## PMM: This is some simple code to demonstrate how PMM works with the `mice` package in R

```{r, eval=FALSE}
# set seed for reproducibility
set.seed(500)
num_imp <- 10 #number of imputations

# mice requires the dataframe to only contain missing variable and its predictors
created_data_for_PMM <- testing_data_only |>
  dplyr::select(confounder, missing_biomarker, outcome, predictor) 

# one imputation of PMM using mice: message suppression needed
imp <- mice(created_data_for_PMM, 
            method = "pmm", 
            m = num_imp) 

# perform multiple imputations and aggregating results with Rubin Rules (RR)
PMM_coefficients <- c()

  for(i in 1:num_imp) {
    imputed_data <- complete(imp, action = i)
    my_reg <- glm(outcome ~ missing_biomarker + confounder,
                  data = imputed_data,
                  family = "binomial")
    
    PMM_coefficients[i] <- summary(my_reg)$coefficients[2]
  }

# quick check on bias of one iteration
mean(PMM_coefficients) - true_effect
```

## CLQI: Perform the algorithm
*As a side note, I may use Rcpp to speed up calculations here*
*As another side note, the Warning is that the solution may be nonunique. This does not matter*

since we are imputing from the study, we do not need to calculate a weighted average.

Instead, we just run a unique logistic regression.

This can be extremely slow, but that is not the concern right now.

If we work with much larger datasets, then we can think of doing a weighted average, which would involve running 99 regressions and using those coefficients instead. 

This would be straightforward to code, but make sure to vectorize correctly!

```{r}
imputation_algorithm <- function(my_data, row_index) {
  
  #generate a random uniform value
  u <- runif(1, min = 0, max = 0.99) 
  
  #perform LQR 
  reg_coeff <- rq(transformed_biomarker ~ outcome + confounder + predictor, 
                        data = my_data, 
                        tau = u)
  
  #save all regression coefficients
  b_intercept <- reg_coeff$coefficients[1]
  b_outcome <- reg_coeff$coefficients[2]
  b_confounder <- reg_coeff$coefficients[3]
  b_predictor <- reg_coeff$coefficients[4]
  
  #predicted imputed value (which is in its transformed state)
  imputation_value_transformed <- b_intercept + (b_outcome * my_data[row_index,]$outcome) + (b_confounder * my_data[row_index,]$confounder) + (b_predictor * my_data[row_index,]$predictor)
  
  #return predicted value
  return(imputation_value_transformed)
}
```

### The following is a demonstration of CLQI with one example for imputation. This is *not* a full implementation with multiple imputations and aggregation with Rubin Rules.

```{r, eval=FALSE}
#generate our data with missing data for the biomarker
data_for_imp <- testing_data_only

#there may be a better way to do this, but for now:
#if our data is missing, we perform the algorithm
  for(row_index in 1:nrow(data_for_imp)) {
    if(is.na(data_for_imp$transformed_biomarker[row_index])) {
      
      imputed_value <- imputation_algorithm(my_data = data_for_imp,
                                            row_index = row_index)
      
      data_for_imp$transformed_biomarker[row_index] <- imputed_value
    }
  }

data_for_imp <- data_for_imp |>
  mutate(untransformed_imputed_biomarker = sapply(transformed_biomarker, inv_log_quant_transform, 
                                                  min = 0, max = q_999999))

data_for_imp #check the transformed_biomarker variable, not the missing_biomarker variable!
```

These are some visualizations for the imputation for CLQI. This is very messy code and is only here for demonstration purposes.

```{r, eval=FALSE}
data_for_imp_new <- data_for_imp

data_for_imp_new$confounder <- factor(data_for_imp_new$confounder, 
                                      levels = c(0, 1), 
                                      labels = c("Confounder = 0", "Confounder = 1"))

# Create the plot with overlaid density curves
ggplot(data = data_for_imp_new, aes(x = biomarker, fill = confounder, color = confounder)) +
  geom_density(alpha = 0.5) + 
  labs(
    title = "Biomarker Distribution by Confounder",
    x = "Biomarker",
    y = "Density"
  ) +
  scale_fill_manual(values = c("skyblue", "orange")) +  # Custom colors for filling
  scale_color_manual(values = c("blue", "red"))        # Custom border colors


ggplot(data = data_for_imp_new, aes(x = untransformed_imputed_biomarker, fill = confounder, color = confounder)) +
  geom_density(alpha = 0.5) + 
  labs(
    title = "Imputed Biomarker Distribution by Confounder",
    x = "Biomarker",
    y = "Density"
  ) +
  scale_fill_manual(values = c("skyblue", "orange")) +  # Custom colors for filling
  scale_color_manual(values = c("blue", "red")) +       # Custom border colors
  stat_function(fun = dchisq, args = list(df = 5), aes(color = NULL), linetype = "dashed", size = 1, color = "black") +
  stat_function(fun = dchisq, args = list(df = 8), aes(color = NULL), linetype = "dotted", size = 1, color = "darkgreen")
```

Lastly, a logistic regression test for *bias*

```{r, eval=FALSE}
CLQI_glm <- glm(outcome ~ untransformed_imputed_biomarker + confounder,
              data = data_for_imp,
              family = "binomial")

summary(CLQI_glm)$coefficients[2] - true_effect
```

# Distance Metrics for Imputation Quality for PMM and CLQI

We can look at histograms with the imputed data and real data all we want, but there must be a way to quantify how different those two distributions are. For our purposes, we have *KS-test*, which is just the maximum vertical Euclidean distance between two distributions (or supremum if you're working with infinitesimals)

```{r, eval=FALSE}
#redo data generation
data_for_imp <- testing_data_only

#separate data for KS test
data_for_imp_zero <- data_for_imp |>
  filter(confounder == 0)

data_for_imp_one <- data_for_imp |>
  filter(confounder == 1)

#comparing with a theoretical chi square distribution from which the data was generated
ks.test(data_for_imp_zero$untransformed_imputed_biomarker, "pchisq", df = 5)
ks.test(data_for_imp_one$untransformed_imputed_biomarker, "pchisq", df = 8)
```

Now we will focus on *1-Wasserstein distance*, which measures the difference between the two distributions throughout their entire support.

```{r, eval=FALSE}
wasserstein_1_distance <- function(variable, my_df) {
  empirical_cdf <- ecdf(variable)
  u <- seq(0, 0.9999999, length.out = 1000) #we will be working with the quantile version. Integration approximation
  
  #now get the quantiles
  empirical_quantiles <- quantile(variable, probs = u)
  theoretical_quantiles <- qchisq(u, df = my_df)
  
  return(mean(as.numeric(abs(empirical_quantiles - theoretical_quantiles))))
}

wasserstein_1_distance(data_for_imp_zero$untransformed_imputed_biomarker, my_df = 5) #from DGM
wasserstein_1_distance(data_for_imp_one$untransformed_imputed_biomarker, my_df = 8) #ditto
```
################################################################################################################
# Simulation Study Functions

We defined a couple of functions to make everything much easier:

*rubin_rule_SE* takes in two vectors: one of the parameter values after performing imputation and one of its associated standard erros. This performs rubin rule calculations to produce the SE. As a reminder, the parameter value is given by taking the average of the `m` imputations

```{r}
#rubin's rule for standard error is complicated, so just keep it in a simple function
rubin_rule_SE <- function(values_MI, SE_MI) { #both inputs are vectors
  variance_within_MI <- mean((SE_MI)^2)
  variance_between_MI <- sum((values_MI - mean(values_MI))^2) / (length(values_MI) - 1)
  total_variance <- variance_within_MI + variance_between_MI + (variance_between_MI / length(values_MI))
  
  return(sqrt(total_variance))
}
```

*A test case has not been implemented, but it should before the final simulation study is done*

*coverage* gives a binary value, 1 if the true parameter is contained in our given CI using the *nominal* rate being 95%, and 0 if not. The logic here should make sense if you know what coverage is

```{r}
coverage <- function(parameter, SE, t_star, true_val) {
  binary <- ifelse(parameter - t_star*SE <= true_val & true_val <= parameter + t_star*SE, 
                   1, 0)
  
  return(binary)
}
```

*A test case has not been implemented, but it should before the final simulation study is done*

*power* gives a binary value.

We know that from our DGM that there is a true different effect, so our estimate should be statistically significant for a difference. How we do this is we calculate a `wald` statistic with a specific `degrees of freedom` given a vector of parameter estimates given from MI and their associated standard errors. If we reject the null with alpha = 0.05, then this function returns 1.

```{r}
power <- function(values_MI, SE_MI, num_MI) {
  #t stat calculation
  wald <- mean(values_MI) / rubin_rule_SE(values_MI, SE_MI)
  
  #df calculation
  variance_within_MI <- mean((SE_MI)^2)
  variance_between_MI <- sum((values_MI - mean(values_MI))^2) / (length(values_MI) - 1)
  my_frac <- variance_between_MI / (num_MI * variance_within_MI)
  df <- ((num_MI - 1) / (1 + my_frac)^2) 
  
  #our p-value
  p_value <- 2 * (1 - pt(abs(wald), df))
  
  #return 1 if we reject H0 (from DGM, we know H1 to be true)
  return(ifelse(p_value < 0.05, 1, 0))
}
```

*A test case has not been implemented, but it should before the final simulation study is done*

## Predictive Mean Matching

In this subsection, we will be defining the PMM function and documenting (in detail) what is going on

```{r}
PMM <- function(my_data, num_MI_iter) {
  suppressMessages({
  suppressWarnings({
  capture.output({
        
      imp <- mice(my_data, method = "pmm", m = num_MI_iter)
        
      values_PMM <- c()
      SE_PMM <- c()
        
      # the for loop to extract values and SE
      for (j in 1:num_MI_iter) {
        imputed_data <- complete(imp, action = j)
        
        my_reg <- glm(outcome ~ missing_biomarker + confounder,
                      data = imputed_data,
                      family = "binomial")
          
        # store these values
        values_PMM[j] <- summary(my_reg)$coefficients["missing_biomarker", "Estimate"]
        SE_PMM[j] <- summary(my_reg)$coefficients["missing_biomarker", "Std. Error"]
      }
        
      results_PMM <- list(values_PMM, SE_PMM)
        
      return(results_PMM)
        
  }) # end capture.output
  }) # end suppressWarnings
  }) # end suppressMessages
}

testing_data_for_PMM <- testing_data_only |>
  dplyr::select(confounder, missing_biomarker, outcome)

a <- PMM(testing_data_for_PMM, num_MI_iter = 10)
as.vector(a[[1]])
```

## CLQI

```{r, eval=FALSE}
values_CLQI <- c()
SE_CLQI <- c()
MI_iter <- 10 
data_for_imp_fresh <- data_generation(sample_size = 1000, missing_prop = 0.3)

for(imp in 1:MI_iter) {
  
  data_for_imp <- data_for_imp_fresh #resets any imputation that happened
  
  for(row_index in 1:nrow(data_for_imp)) {
    if(is.na(data_for_imp$transformed_biomarker[row_index])) {
      imputed_value <- imputation_algorithm(my_data = data_for_imp,
                                            row_index = row_index)
      
      data_for_imp$transformed_biomarker[row_index] <- imputed_value
    }
  }
  
  data_for_imp <- data_for_imp |>
  mutate(untransformed_imputed_biomarker = sapply(transformed_biomarker, inv_log_quant_transform, 
                                                  min = 0, max = q_999999))

  my_glm <- glm(outcome ~ untransformed_imputed_biomarker + confounder,
              data = data_for_imp,
              family = "binomial")

  values_CLQI[imp] <- summary(my_glm)$coefficients[2]
  SE_CLQI[imp] <- summary(my_glm)$coefficients[2,2]
}

      estimated_CLQI <- mean(values_CLQI)
      
      #now FOR COVERAGE
      test_total_SE_PMM <- rubin_rule_SE(values_CLQI, SE_CLQI)
      
      t_star <- qt(0.975, df = 1000 - 1)
      coverage_PMM <- coverage(parameter = mean(values_CLQI),
                                SE = test_total_SE_PMM,
                                t_star = t_star,
                                true_val = true_effect)

      #power
      power_CLQI <- power(values_CLQI, SE_CLQI, MI_iter)
      
      wald_CLQI <- mean(values_CLQI) / rubin_rule_SE(values_CLQI, SE_CLQI)
      wald_CLQI  

values_CLQI
mean(values_CLQI) - true_effect #bias...
```

*A FUNCTION FOR CLQI*

```{r}
CLQI <- function(my_data, num_MI_iter) {
  
  values_CLQI <- c()
  SE_CLQI <- c()
  
  for(imp in 1:num_MI_iter) {
    my_data_iteration <- my_data #resets any imputation that happened
    
    for(row_index in 1:nrow(my_data_iteration)) {
      if(is.na(my_data_iteration$transformed_biomarker[row_index])) {
        imputed_value <- imputation_algorithm(my_data = my_data_iteration,
                                              row_index = row_index)
        
        my_data_iteration$transformed_biomarker[row_index] <- imputed_value
      }
    }
  
  #after running the algorithm, we untransform, perform log reg, save coefficients, rinse and repeat
  my_data_iteration <- my_data_iteration |>
  mutate(untransformed_imputed_biomarker = sapply(transformed_biomarker, inv_log_quant_transform, 
                                                  min = 0, max = q_999999))

  my_glm <- glm(outcome ~ untransformed_imputed_biomarker + confounder,
              data = my_data_iteration,
              family = "binomial")

  values_CLQI[imp] <- summary(my_glm)$coefficients[2]
  SE_CLQI[imp] <- summary(my_glm)$coefficients[2,2]
  } 
  
  CLQI_results <- list(values_CLQI, SE_CLQI)
  return(CLQI_results)
}

testing_data_for_CLQI <- testing_data_only

b <- CLQI(testing_data_for_CLQI, num_MI_iter = 10)
b[1]
```

```{r}
complete_case <- function(my_data) {
  my_glm <- glm(outcome ~ missing_biomarker + confounder,
              data = my_data,
              family = "binomial")
  
  value_CC <- summary(my_glm)$coefficients[2]
  SE_CC <- summary(my_glm)$coefficients[2,2]
  pval_CC <- summary(my_glm)$coefficients["missing_biomarker", "Pr(>|z|)"]
  
  return(c(value_CC, SE_CC, pval_CC))
}

testing_data_for_CC <- testing_data_only

c <- complete_case(testing_data_for_CC)
c[1] #the estimate
```



# MY INITIAL SIMULATION STUDY

```{r}
my_iter_count <- 0

#this is to make reading the code much easier
set.seed(500)
my_sample <- 1000 #sample size for each dataset
num_sim <- 1000 #number of simulations
MI_iter <- 10
prop_data_missing <- 0.3 #proportion of data missing

#here are some vectors we have to define... this is still messy since it's not in a full function
estimate_values_PMM <- c()
SE_values_PMM <- c()
coverage_PMM <- c()
power_PMM <- c()

estimate_values_CLQI <- c()
SE_values_CLQI <- c()
coverage_CLQI <- c()
power_CLQI <- c()

estimate_values_CC <- c()
SE_values_CC <- c()
coverage_CC <- c()
power_CC <- c()

#now for our loop
tictoc::tic() #check runtime for entire simulation
for(i in 1:num_sim) { #for each simulation
  data_for_imp <- data_generation(sample_size = my_sample, 
                                  missing_prop = prop_data_missing) #generate my data
  
  #get values for estimate and SE from PMM
  data_for_imp_PMM <- data_for_imp  |>
    dplyr::select(confounder, missing_biomarker, outcome)
  
  PMM_results <- PMM(data_for_imp_PMM, num_MI_iter = MI_iter) #1 is estimates, 2 is SE
    values_PMM <- as.vector(PMM_results[[1]])
    SE_PMM <- as.vector(PMM_results[[2]])
  
  #perform calculations to get estimate, bias, relative bias, RMSE, coverage, power for PMM
      estimate_values_PMM[i] <- mean(values_PMM)
      SE_values_PMM[i] <- rubin_rule_SE(values_PMM, SE_PMM)
      
      t_star <- qt(0.975, df = my_sample - 1)
      coverage_PMM[i] <- coverage(parameter = estimate_values_PMM[i],
                                  SE = SE_values_PMM[i],
                                  t_star = t_star,
                                  true_val = true_effect)
      
      power_PMM[i] <- power(values_PMM, SE_PMM, MI_iter)
####
  #get values for estimate and SE from CLQI
  CLQI_results <- CLQI(data_for_imp, num_MI_iter = MI_iter) #1 is estimates, 2 is SE
    values_CLQI <- as.vector(CLQI_results[[1]])
    SE_CLQI <- as.vector(CLQI_results[[2]])

  #perform calculations to get estimate, bias, relative bias, RMSE, coverage, power for CLQI
      estimate_values_CLQI[i] <- mean(values_CLQI)
      SE_values_CLQI[i] <- rubin_rule_SE(values_CLQI, SE_CLQI)
      
      t_star <- qt(0.975, df = my_sample - 1)
      coverage_CLQI[i] <- coverage(parameter = estimate_values_CLQI[i],
                                   SE = SE_values_CLQI[i],
                                   t_star = t_star,
                                   true_val = true_effect)
      
      power_CLQI[i] <- power(values_CLQI, SE_CLQI, MI_iter)
#### 
  #perform complete case analysis
  complete_case_results <- complete_case(data_for_imp)
    
  #perform calculations to get estimate, bias, relative bias, RMSE, coverage, power for CC
    estimate_values_CC[i] <- complete_case_results[1]
    SE_values_CC[i] <- complete_case_results[1]
    
    t_star <- qt(0.975, df = my_sample - 1)
    coverage_CC[i] <- coverage(parameter = estimate_values_CC[i],
                               SE = SE_values_CC[i],
                               t_star = t_star,
                               true_val = true_effect)
    
    power_CC[i] <- ifelse(as.numeric(complete_case_results[3]) < 0.05, 1, 0) #if p-val < 0.05, it's 1. Else, it's 0.
    
  #we will be repeating this 1000 times
  my_iter_count <- my_iter_count + 1
  print(my_iter_count)
}
tictoc::toc()

#create bias rows
bias_values_PMM <- estimate_values_PMM - true_effect
bias_values_CLQI <- estimate_values_CLQI - true_effect
bias_values_CC <- estimate_values_CC - true_effect

#and at the end, combine all these vectors into a single dataframe
my_simulation_results_q_999999 <- data.frame(
  estimate_values_PMM = estimate_values_PMM,
  bias_values_PMM = bias_values_PMM,
  SE_values_PMM = SE_values_PMM,
  RMSE_values_PMM = sqrt(bias_values_PMM^2 + SE_values_PMM^2),
  coverage_PMM = coverage_PMM,
  power_PMM = power_PMM, #done
  estimate_values_CLQI = estimate_values_CLQI,
  bias_values_CLQI = bias_values_CLQI,
  SE_values_CLQI = SE_values_CLQI,
  RMSE_values_CLQI = sqrt(bias_values_CLQI^2 + SE_values_CLQI^2),
  coverage_CLQI = coverage_CLQI,
  power_CLQI = power_CLQI, #done
  estimate_values_CC= estimate_values_CC,
  bias_values_CC= bias_values_CC,
  SE_values_CC = SE_values_CC,
  RMSE_values_CC = sqrt(bias_values_CC^2 + SE_values_CC^2),
  coverage_CC = coverage_CC,
  power_CC = power_CC
)

my_simulation_results_q_999999
```

```{r}
#quick bias checks 
(mean(my_simulation_results_q_999999$estimate_values_CLQI) - true_effect) / true_effect * 100
(mean(my_simulation_results_q_999999$estimate_values_PMM) - true_effect) / true_effect * 100
(mean(my_simulation_results_q_999999$estimate_values_CC) - true_effect) / true_effect * 100

#now for RMSE
mean(my_simulation_results_q_999999$RMSE_values_CLQI)
mean(my_simulation_results_q_999999$RMSE_values_PMM)
mean(my_simulation_results_q_999999$RMSE_values_CC)

#now for coverage
mean(my_simulation_results_q_999999$coverage_CLQI)
mean(my_simulation_results_q_999999$coverage_PMM)
mean(my_simulation_results_q_999999$coverage_CC)

#now for power
mean(my_simulation_results_q_999999$power_CLQI)
mean(my_simulation_results_q_999999$power_PMM)
mean(my_simulation_results_q_999999$power_CC)

#save this!
saveRDS(my_simulation_results_q_999999, file="./simulations_setting4.rds")
```



# A SECOND ONE WITH 60 PERCENT

# MY INITIAL SIMULATION STUDY

```{r}
my_iter_count <- 0

#this is to make reading the code much easier
set.seed(500)
my_sample <- 1000 #sample size for each dataset
num_sim <- 1000 #number of simulations
MI_iter <- 25
prop_data_missing <- 0.6 #proportion of data missing

#here are some vectors we have to define... this is still messy since it's not in a full function
estimate_values_PMM <- c()
SE_values_PMM <- c()
coverage_PMM <- c()
power_PMM <- c()

estimate_values_CLQI <- c()
SE_values_CLQI <- c()
coverage_CLQI <- c()
power_CLQI <- c()

estimate_values_CC <- c()
SE_values_CC <- c()
coverage_CC <- c()
power_CC <- c()

#now for our loop
tictoc::tic() #check runtime for entire simulation
for(i in 1:num_sim) { #for each simulation
  data_for_imp <- data_generation(sample_size = my_sample, 
                                  missing_prop = prop_data_missing) #generate my data
  
  #get values for estimate and SE from PMM
  data_for_imp_PMM <- data_for_imp  |>
    dplyr::select(confounder, missing_biomarker, outcome)
  
  PMM_results <- PMM(data_for_imp_PMM, num_MI_iter = MI_iter) #1 is estimates, 2 is SE
    values_PMM <- as.vector(PMM_results[[1]])
    SE_PMM <- as.vector(PMM_results[[2]])
  
  #perform calculations to get estimate, bias, relative bias, RMSE, coverage, power for PMM
      estimate_values_PMM[i] <- mean(values_PMM)
      SE_values_PMM[i] <- rubin_rule_SE(values_PMM, SE_PMM)
      
      t_star <- qt(0.975, df = my_sample - 1)
      coverage_PMM[i] <- coverage(parameter = estimate_values_PMM[i],
                                  SE = SE_values_PMM[i],
                                  t_star = t_star,
                                  true_val = true_effect)
      
      power_PMM[i] <- power(values_PMM, SE_PMM, MI_iter)
####
  #get values for estimate and SE from CLQI
  CLQI_results <- CLQI(data_for_imp, num_MI_iter = MI_iter) #1 is estimates, 2 is SE
    values_CLQI <- as.vector(CLQI_results[[1]])
    SE_CLQI <- as.vector(CLQI_results[[2]])

  #perform calculations to get estimate, bias, relative bias, RMSE, coverage, power for CLQI
      estimate_values_CLQI[i] <- mean(values_CLQI)
      SE_values_CLQI[i] <- rubin_rule_SE(values_CLQI, SE_CLQI)
      
      t_star <- qt(0.975, df = my_sample - 1)
      coverage_CLQI[i] <- coverage(parameter = estimate_values_CLQI[i],
                                   SE = SE_values_CLQI[i],
                                   t_star = t_star,
                                   true_val = true_effect)
      
      power_CLQI[i] <- power(values_CLQI, SE_CLQI, MI_iter)
#### 
  #perform complete case analysis
  complete_case_results <- complete_case(data_for_imp)
    
  #perform calculations to get estimate, bias, relative bias, RMSE, coverage, power for CC
    estimate_values_CC[i] <- complete_case_results[1]
    SE_values_CC[i] <- complete_case_results[1]
    
    t_star <- qt(0.975, df = my_sample - 1)
    coverage_CC[i] <- coverage(parameter = estimate_values_CC[i],
                               SE = SE_values_CC[i],
                               t_star = t_star,
                               true_val = true_effect)
    
    power_CC[i] <- ifelse(as.numeric(complete_case_results[3]) < 0.05, 1, 0) #if p-val < 0.05, it's 1. Else, it's 0.
    
  #we will be repeating this 1000 times
  my_iter_count <- my_iter_count + 1
  print(my_iter_count)
}
tictoc::toc()

#create bias rows
bias_values_PMM <- estimate_values_PMM - true_effect
bias_values_CLQI <- estimate_values_CLQI - true_effect
bias_values_CC <- estimate_values_CC - true_effect

#and at the end, combine all these vectors into a single dataframe
my_simulation_results_60 <- data.frame(
  estimate_values_PMM = estimate_values_PMM,
  bias_values_PMM = bias_values_PMM,
  SE_values_PMM = SE_values_PMM,
  RMSE_values_PMM = sqrt(bias_values_PMM^2 + SE_values_PMM^2),
  coverage_PMM = coverage_PMM,
  power_PMM = power_PMM, #done
  estimate_values_CLQI = estimate_values_CLQI,
  bias_values_CLQI = bias_values_CLQI,
  SE_values_CLQI = SE_values_CLQI,
  RMSE_values_CLQI = sqrt(bias_values_CLQI^2 + SE_values_CLQI^2),
  coverage_CLQI = coverage_CLQI,
  power_CLQI = power_CLQI, #done
  estimate_values_CC= estimate_values_CC,
  bias_values_CC= bias_values_CC,
  SE_values_CC = SE_values_CC,
  RMSE_values_CC = sqrt(bias_values_CC^2 + SE_values_CC^2),
  coverage_CC = coverage_CC,
  power_CC = power_CC
)

my_simulation_results_60
```

```{r}
#quick bias checks 
(mean(my_simulation_results_60$estimate_values_CLQI) - true_effect) / true_effect * 100
(mean(my_simulation_results_60$estimate_values_PMM) - true_effect) / true_effect * 100
(mean(my_simulation_results_60$estimate_values_CC) - true_effect) / true_effect * 100

#now for RMSE
mean(my_simulation_results_60$RMSE_values_CLQI)
mean(my_simulation_results_60$RMSE_values_PMM)
mean(my_simulation_results_60$RMSE_values_CC)

#now for coverage
mean(my_simulation_results_60$coverage_CLQI)
mean(my_simulation_results_60$coverage_PMM)
mean(my_simulation_results_60$coverage_CC)

#now for power
mean(my_simulation_results_60$power_CLQI)
mean(my_simulation_results_60$power_PMM)
mean(my_simulation_results_60$power_CC)

#save this!
saveRDS(my_simulation_results_60, file="./simulations_setting_60_perc.rds")
```









Now a check!

```{r}
simulation_setting_30_perc <- readRDS(file="./sim_results/simulations_setting4.rds")

sim_setting_long <- simulation_setting_30_perc |>
  dplyr::select(estimate_values_CLQI, estimate_values_PMM) |>
  rename(CLQI = estimate_values_CLQI, PMM = estimate_values_PMM) |> #rename so i don't have to do weird legend things
  pivot_longer(cols = everything(),
               names_to = "method",
               values_to = "value")
#my ggplot!
ggplot(sim_setting_long, aes(x = value, color = method, fill = method)) +
  geom_density(alpha = 0.2) +
  geom_vline(xintercept = true_effect, linetype = "dashed", color = "black") +
  labs(title = "Density Plot of Estimates", 
       x = "Estimate Value", 
       y = "Density") + 
  theme(text = element_text(size = 13))
```

#################################################################################

```{r}
# Plot histogram of your biomarker data
hist(created_data$biomarker, probability = TRUE, breaks = 100,
     col = "lightgray", border = "white",
     main = "Empirical Biomarker vs. Theoretical Mixture",
     xlab = "Biomarker")

# Generate a sequence of x-values covering the range of your data
x_vals <- seq(min(created_data$biomarker), 
              quantile(created_data$biomarker, 0.99), 
              length.out = 1000)

# Calculate theoretical mixture density
mixture_density <- 0.6 * dchisq(x_vals, df = 5) + 0.4 * dchisq(x_vals, df = 8)

# Overlay the theoretical density curve
lines(x_vals, mixture_density, col = "red", lwd = 2)

# Add a legend
legend("topright", legend = "Theoretical Mixture: 0.6 * χ²(5) + 0.4 * χ²(8)",
       col = "red", lwd = 2, bty = "n")
```

