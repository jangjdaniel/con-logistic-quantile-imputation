
This qmd is a modified version of `one_basis_study_scenerio.qmd` that cleaned up everything so we can get results for the simulation study. We will be testing 8 scenerios, all with one missing study and one basis study

- Two sample sizes (n=500, n=1500)
- Two LD ranges (~30%, ~60%)
- Two levels of heterogeneity (Small: 0.01, Large: 0.1)

My hope is that this qmd is easily readable. If not, please contact me: djang26@amherst.edu

```{r}
#necessary libraries
library(tidyverse)
library(ggplot2)
library(quantreg)
library(MASS)
library(purrr)
library(tictoc)
```

These are necessary transformation functions that we will be using throughout this study

```{r}
#logit and expit functions for myself
logit <- function(prob) {
  value <- log(prob / (1 - prob))
  return(value)
}

expit <- function(prob) {
  value <- 1 / (1 + exp(-(prob)))
  return(value)
}

#now some other transformation functions
log_quant_transform <- function(value, min, max) {
  new_value <- log((value - min) / (max - value))
  
  if (is.nan(new_value)) {return(NA)} #negative log values return an NA. Will be important to address
  else {return(new_value)}
}

inv_log_quant_transform <- function(value, min, max) {
  new_value <- (exp(value)*max + min) / (1+exp(value))
  return(new_value)
}
```

`coefficient_generator` generates coefficients for our two studies to be generated out of
Tau represents our heterogenity among studies. The higher the value, the more variable the coefficients are between each iteration
We chose the point values for the coefficients based off of the previous paper introducing CQI for consistency

This function outputs a dataset including all the necessary information from which the distributions that the data are generated from are

```{r}
coefficient_generator <- function(tau, num_studies, 
                                  a_0 = logit(0.3), a_1 = log(1.1), 
                                  b_0 = logit(0.1), b_1 = log(1.5), b_2 = log(0.7), b_3 = log(1.2)) {
    
  #create which number study we have
  study_counts <- data.frame(id = 1:num_studies)
  
  study_counts <- study_counts |>
    mutate(study_num = paste("Study", id)) |>
    dplyr::select(study_num)
  
  #allow a_1 to vary
  alpha_coefficients <- rnorm(num_studies, a_1, tau)
  alpha_coefficients <- as.data.frame(alpha_coefficients) #make into data frame
  
      #renaming for better binding experience + adding a_0... not important here
      alpha_coefficients <- alpha_coefficients |> 
        mutate(a_0 = a_0) |>
        rename(a_1 = "alpha_coefficients") |>
        dplyr::select(a_0, a_1) #reordering
  
      
  #now doing the beta coefficients
  beta_vector <- c(b_1, b_2, b_3)
  
    #variance-covariance matrix
    matrix_size <- length(beta_vector)
    diag_mat <- matrix(0, matrix_size, matrix_size) 
    diag(diag_mat) <- 1 #make all the diagonals 1 for the identity matrix
    
    #lastly, we need to perform the calculation specified in section 3.1.4
    beta_matrix <- tau * diag_mat
    beta_coefficients <- mvrnorm(num_studies, beta_vector, beta_matrix)
    beta_coefficients <- as.data.frame(beta_coefficients)
    
      #renaming for better binding experience
      beta_coefficients <- beta_coefficients |> 
        mutate(b_0 = b_0) |>
        rename(b_1 = "V1", b_2 = "V2", b_3 = "V3") |>
        dplyr::select(b_0, b_1, b_2, b_3)
  
  #lastly, we need a range of degrees of freedom for the confounder generation
  #there will be two just in case I want to use an F distribution
  deg_freedom <- data.frame(df_1 = round(runif(num_studies, min = 3, max = 7)),
                            df_2 = round(runif(num_studies, min = 3, max = 7)))
  
  #now combine these results
  coefficients <- cbind(study_counts, alpha_coefficients, beta_coefficients, deg_freedom)
  
  return(coefficients)
}
```

`create_data` creates a single dataset based on a given sample size and specified coefficients

```{r}
#this will be nested to make the list function cleaner to read
create_data <- function(sample_size, a_0, a_1, b_0, b_1, b_2, b_3, df_1, df_2) {
  
  #initialize everything
  n <- sample_size
  
  #step 1: Base Binary Predictor
  V <- rbinom(n, size = 1, prob = 0.4)
  
  #step 2: cnfounder with a skewed distribution... Biomarker missing
  C1 <- rchisq(n, df = df_1) 
  #C2 <- rnorm(n, mean = 75, sd = 7) #another confounder with a normal distribution. not used right now
  
  #step 3: generating exposure variable based on confounders (probability)
  E <- expit(a_0 + a_1*C1)
  E_bin <- rbinom(n, size = 1, prob = E)
  
  #step 4: generating outcome based on confounders, exposure, and base binary predictor
  O <- expit(b_0 + b_1*E + b_2*V + b_3*C1)
  O_bin <- rbinom(n, size = 1, prob = O)
  
  #step 5: create dataset
  
  my_data <- data.frame(
    predictor = V,
    confounder_1 = C1,
    exposure = E_bin,
    outcome = O_bin
  )
  
  return(my_data)
} 
```

`create_multiple_datasets` uses `create_data` to, well you guessed it, create multiple datasets. The distributions from which the data are generated for each dataset comes from information we get from `coefficient_generator`

```{r}
#recall all coefficients are stored in coefficient_generator funct
create_multiple_datasets <- function(study_coefficient_dataset, sample_size) {
  my_list <- list() #initialize empty list
  
  #pulling all values we need
  a_0_values <- study_coefficient_dataset |> dplyr::pull(a_0)
  a_1_values <- study_coefficient_dataset |> dplyr::pull(a_1)
  b_0_values <- study_coefficient_dataset |> dplyr::pull(b_0)
  b_1_values <- study_coefficient_dataset |> dplyr::pull(b_1)
  b_2_values <- study_coefficient_dataset |> dplyr::pull(b_2)
  b_3_values <- study_coefficient_dataset |> dplyr::pull(b_3)
  
  #also degrees of freedom
  df_1_values <- study_coefficient_dataset |> dplyr::pull(df_1)
  df_2_values <- study_coefficient_dataset |> dplyr::pull(df_2)
  
  for(i in 1:nrow(study_coefficient_dataset)) {
    #do the data generating mechanism
    a_0 <- a_0_values[i]
    a_1 <- a_1_values[i]
    b_0 <- b_0_values[i]
    b_1 <- b_1_values[i]
    b_2 <- b_2_values[i]
    b_3 <- b_3_values[i]
    
    #also the degrees of freedom
    df_1 <- df_1_values[i]
    df_2 <- df_2_values[i]
    
    #apply the data generating mechanism function from the values above
    my_data <- create_data(sample_size = sample_size, 
                           a_0 = a_0, 
                           a_1 = a_1, 
                           b_0 = b_0, 
                           b_1 = b_1, 
                           b_2 = b_2, 
                           b_3 = b_3,
                           df_1 = df_1,
                           df_2 = df_2)
    
    
    #finally, add this dataset to our list
    my_list[[i]] <- my_data
  
  }
  
  #return the list
  return(my_list)
}
```

Last but not least, `data_generating_mechanism` creates our datasets with the LD missingness added. We cannot extract the true coefficients from this function (to keep things simple), but with some modification, you can do that. 

*Warning: The LD should be chosen from this, which means I have to edit my functions later*

```{r}
data_generating_mechanism <- function(sample_size, LD, tau) {
  
  #first, create my studies based on coefficients
  my_coefficients <- coefficient_generator(tau = tau, num_studies = 2) #2 is consistent here
  my_studies <- create_multiple_datasets(my_coefficients, sample_size = sample_size)
  
  #log transform our data
  min = 0
  max = ceiling(quantile(my_studies[[1]]$confounder_1, prob = 0.99))
  
  suppressWarnings({ #a lot of warnings... some will be NA i know.
    my_studies[[1]] <- my_studies[[1]] |>
      mutate(confounder_1_transformed = sapply(confounder_1, log_quant_transform, min, max))
  })
  
  #define the LD and make data missing based on that
  biomarker_values <- my_studies[[2]]$confounder_1
  LoD_value <- as.numeric(quantile(biomarker_values, LD)) #must be given as a decimal
  
  #now we made the data missing based on our given LD, and also transform this value
  my_studies[[2]] <- my_studies[[2]] |>
    mutate(confounder_1_missing = ifelse(confounder_1 >= LoD_value, confounder_1, NA))
  
  #just to be able to look into my_coefficients later
  my_studies <- list(my_studies[[1]], my_studies[[2]], my_coefficients)
  return(my_studies) #return list of studies with missingness added
}
```


**************************************************************************************

Here are some more functions that will be running our algorithm, along with definitions on what exactly they do

`logistic_quantile_regression_coefficients` creates our set of regression coefficients from our *basis study* to send to the *missing study*. It outputs a dataset of the coefficients, ready for quantile regression

```{r}
logistic_quantile_regression_coefficients <- function(basis_study) {
 
  coefficient_data <- data.frame() #initiliaze empty data frame
  
  for(i in seq(from = 0.01, to = 0.99, by = 0.01)) {
    reg_coeff <- rq(confounder_1_transformed ~ exposure + predictor + outcome, data = basis_study, tau=i)
    
    new_data <- data.frame(
      b0 = reg_coeff$coefficients[1],
      b_exposure = reg_coeff$coefficients[2],
      b_predictor = reg_coeff$coefficients[3],
      b_outcome = reg_coeff$coefficients[4],
      quant = i)
    
    coefficient_data <- rbind(coefficient_data, new_data) #add to new iterations
  }
  return(coefficient_data)
}
```

`find_prop_missing` finds the proportion of LD data for the missing study. This will end up being useful. It will report a whole number

```{r}
#make this into a function for easy use?
find_prop_missing <- function(missing_data_study, LD) {
  prop_missing <- sum(is.na(missing_data_study[[LD]])) / nrow(missing_data_study)
  prop_missing <- ceiling(prop_missing * 100)
  
  return(prop_missing)
}
```

`uniform_values` generates a random value from a unif(1,99) distribution, then extracts the floor, ceiling, and modulus for the CLQI algorithm

```{r}
uniform_values <- function(specified_max) {
  u <- runif(1, min = 1, max = specified_max) #aka from 0.01 to 0.99
  
  #all the values we need from the uniform
  floor_u <- floor(u)
  mod_u <- (u - floor(u))
  next_u <- ceiling(u)
  
  #now putting this into a vector
  my_u <- c(u, floor_u, mod_u, next_u)
  return(my_u)
}
```

`imputation_algorithm` is the function that implements imputation for one missing value
We can use tidyverse functionality to slightly modify the use of this function, *although that may be computationally inefficient*

```{r}
imputation_algorithm <- function(basis_coefficients, study_for_imputation, 
                                 var_for_imputation, row_index, u_vector) {
  
  u_vector <- u_vector
  floor_quantile <- basis_coefficients[u_vector[2], ] #floor
  ceiling_quantile <- basis_coefficients[u_vector[4], ] #ceiling
  
  #need to calculate regression values... really messy don't look at this
  lower_quantile_value <- floor_quantile$b0 + (floor_quantile$b_predictor * study_for_imputation[row_index,]$predictor) +
    (floor_quantile$b_exposure * study_for_imputation[row_index,]$exposure) + (floor_quantile$b_outcome * study_for_imputation[row_index,]$outcome)

  upper_quantile_value <- ceiling_quantile$b0 + (ceiling_quantile$b_predictor * study_for_imputation[row_index,]$predictor) +
    (ceiling_quantile$b_exposure * study_for_imputation[row_index,]$exposure) + (ceiling_quantile$b_outcome * study_for_imputation[row_index,]$outcome)

  modulus <- u_vector[3]
  imputation_value_transformed <- ((1-modulus)*lower_quantile_value) + (modulus*upper_quantile_value)
  
  #lastly, untransform this value using the right min and max... organization is a headache
  min_imp <- 0
  missing_data_proportion <- find_prop_missing(missing_data_study = study_for_imputation, 
                                               LD = as.character(var_for_imputation)) / 100
  
  #THIS IS THE ISSUE...
  max_imp <- as.numeric(quantile(study_for_imputation$confounder_1, missing_data_proportion))
  #then normal distribution to add random error... AHHHHHHH
  
  #remember min is 0 and prop_missing gives us the right quantile for calculating max from study_for_imputation
  imputed_value_regular <- inv_log_quant_transform(value = imputation_value_transformed, 
                                                   min = min_imp, 
                                                   max = max_imp)
  
  return(imputed_value_regular)
}
```

```{r, eval=FALSE}
#test case!
jokes_are_funny <- data_generating_mechanism(sample_size = 500, 
                                       LD = 0, #placeholder
                                       tau = 0.01)

#our studies!
basis_study <- as.data.frame(jokes_are_funny[[1]])
missing_study <- as.data.frame(jokes_are_funny[[2]])
the_LD <- min(missing_study$confounder_1_missing, na.rm=TRUE)

#create basis coefficients
basis_regression_coefficents <- logistic_quantile_regression_coefficients(basis_study) #created from sim_data
prop <- find_prop_missing(missing_study, "confounder_1_missing")

#generate ONE uniform value
my_uniform_values <- uniform_values(specified_max = prop)

#now apply the algorithm; recall we need to loop through this 10 times for this to be MI
missing_study_fixed_MI <- missing_study |>
  mutate(confounder_1_fixed_MI = ifelse(is.na(confounder_1_missing), 
                                        imputation_algorithm(basis_coefficients = basis_regression_coefficents, 
                                                 study_for_imputation = missing_study, 
                                                 var_for_imputation = "confounder_1_missing",
                                                 row_index = seq_len(nrow(missing_study)), 
                                                 u_vector = my_uniform_values), 
                                        confounder_1_missing))

#this function doesn't automatically do the regression sadly

log_reg_result <- glm(outcome ~ exposure + predictor + confounder_1_fixed_MI, 
                          data = missing_study_fixed_MI, 
                          family = "binomial")
  
exp(log_reg_result$coefficients[2]) - 1.1 #bias

#variance
(summary(log_reg_result)$coefficients[2, 2])^2 #the first 2 is for exposure, and the second 2 is for accessing the standard error
```

The `fixed_MI` function performs the fixed multiple imputation algorithm of the CLQI algorithm (aka instead of a random uniform for every missing value, we choose one uniform value for the entire imputation, then do the imputations 10 times and combine using rubin's rules)

```{r}
fixed_MI <- function(num_iterations = 10, missing_dataset, 
                    basis_coefficients, var_for_imputation, #var_for_imputation is no longer used
                    specified_max) {
  
  b1_coefficients <- numeric(num_iterations)
  b1_variance <- numeric(num_iterations)
  
  for(i in 1:num_iterations) {
  
    #generate ONE uniform value
    my_uniform_values <- uniform_values(specified_max = specified_max)
    
    
    fixed_MI_dataset <- missing_dataset |>
      mutate(confounder_1_fixed_MI = ifelse(is.na(confounder_1_missing), 
                                            imputation_algorithm(basis_coefficients = basis_coefficients, 
                                                                 study_for_imputation = missing_dataset, 
                                                                 var_for_imputation = "confounder_1_missing", 
                                                                 row_index = seq_len(nrow(missing_dataset)), 
                                                                 u_vector = my_uniform_values),
                                            confounder_1_missing)
             )
    
    #then run logistic regression
    log_reg_result <- glm(outcome ~ exposure + predictor + confounder_1_fixed_MI, 
                          data = fixed_MI_dataset, 
                          family = "binomial")
      

    #store the b1 parameter in a vector
    b1_coefficients[i] <- exp(log_reg_result$coefficients[2])
    b1_variance[i] <- (summary(log_reg_result)$coefficients[2,2])^2
  }
  
  #now put the parameter estimates and their associated variances in a dataframe and return that for each MI iteration
  coefficients_and_variance <- data.frame(coefficients = b1_coefficients,
                                          variance = b1_variance)
  
  return(coefficients_and_variance)
}
```

```{r, eval=FALSE}
#test case 2
jokes_are_funny <- data_generating_mechanism(sample_size = 500, 
                                       LD = 0, #placeholder
                                       tau = 0.01)

#our studies!
basis_study <- as.data.frame(jokes_are_funny[[1]])
missing_study <- as.data.frame(jokes_are_funny[[2]])
the_LD <- min(missing_study$confounder_1_missing, na.rm=TRUE)

#create basis coefficients
basis_regression_coefficents <- logistic_quantile_regression_coefficients(basis_study) #created from sim_data
prop <- find_prop_missing(missing_study, "confounder_1_missing")


fixed_MI_results <- fixed_MI(missing_dataset = missing_study,
                             basis_coefficients = basis_regression_coefficents,
                             specified_max = prop)

mean(fixed_MI_results) - 1.1 #here is our bias!
```


`CLQI_algorithm` is the function that applies the previous few functions and imputes a unique imputed value to each missing observation. This returns a dataset with one full imputation, ready for checking

```{r}
#this is the CLQI algorithm, with some modifications to the u_vector idea
#for fixed MI, just move where the my_uniform_values gets called, so we use the same uniform value each time
#sadly this is not efficient, but for readability, and also for me to not go insane, this is what I did

CLQI_algorithm <- function(missing_dataset, basis_coefficients, specified_max) {

  missing_dataset$confounder_1_CLQI <- NA #initialize a new variable here... base R ugh
  
  for(row_index in 1:nrow(missing_dataset)) {
    if(is.na(missing_dataset$confounder_1_missing[row_index])) {
      my_uniform_values <- uniform_values(specified_max) #generate unique uniform values
      
      imputed_value <- imputation_algorithm(basis_coefficients = basis_coefficients, 
                                study_for_imputation = missing_dataset, 
                                var_for_imputation = "confounder_1_missing",
                                row_index = row_index, #to get the right one
                                u_vector = my_uniform_values)
      
      missing_dataset$confounder_1_CLQI[row_index] <- imputed_value
    }
    else {
      missing_dataset$confounder_1_CLQI[row_index] <- missing_dataset$confounder_1_missing[row_index]
    }
  }
  
  return(missing_dataset)
}
```

`CLQI_MI` applies the CLQI algorithm to the missing_dataset 10 times and combines the results according to rubin's rules

```{r}
CLQI_MI <- function(num_iterations = 10, missing_dataset, 
                    basis_coefficients, var_for_imputation, #var_for_imputation is no longer used
                    specified_max) {
  
  b1_coefficients <- numeric(num_iterations) #initialize vector
  b1_variance <- numeric(num_iterations) #initialize vector
  
  for(i in 1:num_iterations) {
    #run the algorithm
    missing_dataset_imputed <- CLQI_algorithm(missing_dataset, basis_coefficients, specified_max)
      
    #run logistic regression
    log_reg_result <- glm(outcome ~ exposure + predictor + confounder_1_CLQI, 
                          data = missing_dataset_imputed, 
                          family = "binomial")
      
    #extract exposure coefficients (b1)
    b1_coefficients[i] <- exp(log_reg_result$coefficients[2])
    b1_variance[i] <- summary(log_reg_result)$coefficients[2,2]^2
  }
  
  #now make a dataframe for the coefficients and variance for each MI iteration
  coefficients_and_variance <- data.frame(coefficients = b1_coefficients,
                                          variance = b1_variance)
  
  return(coefficients_and_variance)
}
  
```

```{r, eval=FALSE}
#test case!
```


`constant_imputation` applies constant imputation to all missing values for *confounder_1_missing* and presents the b1 coefficient as a result

```{r}
constant_imputation <- function(missing_dataset, var_for_imputation, LD) {
  
  missing_dataset_constanted <- missing_dataset |>
    dplyr::mutate(confounder_1_sqrt2_imp = ifelse(is.na(confounder_1_missing), 
                                                  (LD / sqrt(2)), 
                                                  confounder_1_missing))
  
  log_reg_result <- glm(outcome ~ exposure + predictor + confounder_1_sqrt2_imp, 
                          data = missing_dataset_constanted, 
                          family = "binomial")
  
  constant_imp_result <- c(exp(log_reg_result$coefficients[2]), summary(log_reg_result)$coefficients[2,2]^2)
  
  return(constant_imp_result) #for the exposure variable
}
```

```{r, eval=FALSE}
#test case
jokes_are_funny <- data_generating_mechanism(sample_size = 500, 
                                       LD = 0, #placeholder
                                       tau = 0.01)

constant_imp_test <- constant_imputation(missing_dataset = as.data.frame(jokes_are_funny[2]), 
                         LD = as.data.frame(jokes_are_funny[3])$LoD[2]) #LD should be min(confounder_1_missing) in real testing

constant_imp_test
```

`complete_case_analysis` does... well... complete case analysis? takes away the NA and performs regression. BAD IN PRACTICE !

```{r}
complete_case_analysis <- function(missing_dataset, var_for_imputation) {
  
  CC_missing_dataset <- missing_dataset |>
    filter(!is.na(confounder_1_missing)) #only keep the values where confounder_1_missing is still observed
  
  log_reg_result <- glm(outcome ~ exposure + predictor + confounder_1_missing, 
                          data = CC_missing_dataset, 
                          family = "binomial")
  
  CC_results <- c(exp(log_reg_result$coefficients[2]), summary(log_reg_result)$coefficients[2,2]^2)
  
  return(CC_results) #for the exposure variable
}
```

```{r, eval=FALSE}
#another test case
jokes_are_funny <- data_generating_mechanism(sample_size = 500, 
                                             LD = 0, #placeholder
                                             tau = 0.01)

complete_case_test <- complete_case_analysis(missing_dataset = as.data.frame(jokes_are_funny[2]))

complete_case_test
```

`rubin_rules` is a function that performs rubin's rules on the MI results for both CLQI_MI and fixed_MI

```{r}
rubin_rules <- function(estimate_and_variance) {
  #the parameter result
  coefficient_MI <- mean(estimate_and_variance$coefficients)
  
  #the variance result
  variance_MI <- mean(estimate_and_variance$variance)
  
  #return a vector, where [1] is the estimate and [2] is the variance
  my_vector <- c(coefficient_MI, variance_MI)
  return(my_vector)
}
```


**************************************************************************************

We will now perform Setting 1 of the simulation study. This will serve as a closer step-by-step guide on how the study is performed
- n = 500
- LD ~ 30%
- Small Heterogeneity (tau = 0.01)

```{r}
set.seed(605) #set seed for reproducibility

my_sample_size = 500
my_tau = 0.01
```

Recall that we need to run the data generating mechanism for each simulation iteration, as well as proceed with the CLQI algorithm, Fixed MI, constant imputation, and complete case (CC) analysis. 

The workflow will look as follows *for each iteration*:
- Generate data with new set of coefficients each time
>> Remember to extract the list with basis_study and missing_study so code works later on...

- Run the conditional logistic quantile regressions to extract regression coefficients to "send over" to missing study
- Missing Study performs CLQI, as well as the other imputation methods (fixed MI, constant)
- Do logistic regression to get b1 coefficient for each method. Don't forget Complete Case (CC)
>> Don't forget to do the MI thing for CLQI, repeating the algorithm 10 times so that we can get an aggregate result
>> This also applies to fixed MI. We must do it 10 times

- Store all necessary information for bias, MSE, coverage, etc into a new dataset
- Rinse and repeat 1000 times for the simulation setting


**************************************************************************************

`one_iteration` will provide one iteration of the simulation, utilizing most, if not all, the functions we defined previously
This function will return a list of some important values 

```{r}
one_iteration <- function(specified_sample_size, specified_tau, specified_LD) {
  #generate the data
  
  #create the data here so we can do the same imputation with the same data
  my_data <- data_generating_mechanism(sample_size = specified_sample_size, 
                                       LD = specified_LD, 
                                       tau = specified_tau)
  
  #our studies!
  basis_study <- as.data.frame(my_data[[1]])
  missing_study <- as.data.frame(my_data[[2]])
  the_LD <- min(missing_study$confounder_1_missing, na.rm=TRUE)
  
  #CLQI
    #the basis dataset runs conditional logistic quantile regression
    basis_regression_coefficents <- logistic_quantile_regression_coefficients(basis_study) #created from my_data
    prop <- find_prop_missing(missing_study, "confounder_1_missing")
    
  #the CLQI_MI results
    CLQI_MI_results <- CLQI_MI(num_iterations = 10, 
                               missing_dataset = missing_study, #created from my_data
                               basis_coefficients = basis_regression_coefficents, 
                               var_for_imputation = "confounder_1_missing", #again not used
                               specified_max = prop) 
    
    #combine these results using rubin's rules (since the function returns the 10 iterations from MI)
    CLQI_MI_results <- rubin_rules(CLQI_MI_results)
  
  #the fixed MI results
    fixed_MI_results <- fixed_MI(num_iterations = 10,
                                 missing_dataset = missing_study,
                                 basis_coefficients = basis_regression_coefficents,
                                 specified_max = prop)
    
    #combine these results using rubin's rules (since the function returns the 10 iterations from MI)
    fixed_MI_results <- rubin_rules(fixed_MI_results)
    
###############################################################################################
  #the constant imputation results
    constant_imputation_sqrt_2_results <- constant_imputation(missing_dataset = missing_study, 
                                                              LD = the_LD)

  #the complete case results
    complete_case_results <- complete_case_analysis(missing_dataset = missing_study)
  
###############################################################################################
  #turning this into a vector: the specific order of our methods will matter
  imputation_results_vector <- data.frame(estimate_CLQI = CLQI_MI_results[1],
                                          variance_CLQI = CLQI_MI_results[2],
                                          estimate_fixed_MI = fixed_MI_results[1],
                                          variance_fixed_MI = fixed_MI_results[2],
                                          estimate_constant = constant_imputation_sqrt_2_results[1],
                                          variance_constant = constant_imputation_sqrt_2_results[2],
                                          estimate_CC = complete_case_results[1],
                                          variance_CC = complete_case_results[2])
    
  return(imputation_results_vector)
}
```

```{r, eval=FALSE}
#test case!
one_iteration(specified_sample_size = 500, 
              specified_tau = 0.01, 
              specified_LD = 0.30)
```

`repetera_full_simulation` is the function that runs `one_iteration` the specified number of times (for readability sakes... everything should be a function)! This is Swedish for "repeat" (duh) to celebrate my time in Stockholm :)

This doesn't necessarily have to be a function, but for repeating this so many times, I think it should...

Lastly, we take these results for each method tested (CLQI, Fixed MI, constant, CC) and calculate the bias, MSE, *coverage rate*, *etc*

```{r}
repetera_full_simulation <- function(specified_sample_size, specified_tau, specified_LD, sim_size, b1_true) {
  
  sim_results <- purrr::map_dfr(1:sim_size, ~ {
  
  # We go through one iteration of the simulation
  parameter_est <- one_iteration(specified_sample_size = specified_sample_size, 
                                 specified_tau = specified_tau,
                                 specified_LD = specified_LD)
  
  # Return the result of the current iteration
  parameter_est
  })
  
  #now for coverage: need to calculate based on a condition
  t_star <- qt(0.975, specified_sample_size - 1)
  
  
  #after, we will calculate the statistics we desire... STILL HAVE NOT DONE COVERAGE YET
    sim_results_send <- sim_results |>
      mutate(bias_CLQI = estimate_CLQI - b1_true,
             MSE_CLQI = (bias_CLQI)^2 + variance_CLQI,
             coverage_CLQI = ifelse(estimate_CLQI - (t_star*sqrt(variance_CLQI)) <= b1_true & b1_true <= estimate_CLQI + (t_star*sqrt(variance_CLQI)), 1, 0),
             bias_fixed_MI = estimate_fixed_MI - b1_true,
             MSE_fixed_MI = (bias_fixed_MI)^2 + variance_fixed_MI,
             coverage_fixed_MI = ifelse(estimate_fixed_MI - (t_star*sqrt(variance_fixed_MI)) <= b1_true & b1_true <= estimate_fixed_MI + (t_star*sqrt(variance_fixed_MI)), 1, 0),
             bias_constant = estimate_constant - b1_true,
             MSE_constant = (bias_constant)^2 + variance_constant,
             coverage_constant = ifelse(estimate_constant - (t_star*sqrt(variance_constant)) <= b1_true & b1_true <= estimate_constant + (t_star*sqrt(variance_constant)), 1, 0),
             bias_CC = estimate_CC - b1_true,
             MSE_CC = (bias_CC)^2 + variance_CC,
             coverage_CC = ifelse(estimate_CC - (t_star*sqrt(variance_CC)) <= b1_true & b1_true <= estimate_CC + (t_star*sqrt(variance_CC)), 1, 0)
             ) 
  
  return(sim_results_send)
}
```

**************************************************************************************

This purrr loop (like a for loop but more efficient for R) just runs the `one_iteration` function multiple times (1000 times for a sim study). We get our estimates for the coefficient, as well as its associated variance. 

```{r}
tictoc::tic() #start the timer to check

sim_setting_1_results <- repetera_full_simulation(specified_sample_size = 500, 
                                                 specified_tau = 0.01, 
                                                 specified_LD = 0.30, #30% missing data
                                                 sim_size = 1000,
                                                 b1_true = exp(log(1.1)))

tictoc::toc() # Finish the computation time
```

```{r}
#save the results and look at them!
saveRDS(sim_setting_1_results, file="./simulation_results/sim_setting_1.rds")
```


```{r}
sim_setting_1_results <- readRDS(file="./simulation_results/sim_setting_1.rds")

ggplot(data=sim_setting_1_results, aes(x=bias_fixed_MI)) +
  geom_density() +
  geom_vline(aes(xintercept = mean(bias_CLQI)), color = "red", linetype = "dashed", size = 1) +
  theme_bw()
```

```{r}
sim_setting_1_results_bias <- sim_setting_1_results |>
  pivot_longer(cols = c(bias_fixed_MI, bias_CLQI, bias_constant, bias_CC), 
               names_to = "bias_type", 
               values_to = "bias_value")

# Plot the density of each bias type with separate graphs
ggplot(sim_setting_1_results_bias, aes(x = bias_value, fill = bias_type)) +
  geom_density(alpha = 0.25) +  # Adjust transparency with alpha
  geom_vline(data = sim_setting_1_results_bias %>%
               group_by(bias_type) %>%
               summarize(mean_bias = mean(bias_value)), 
             aes(xintercept = mean_bias, color = bias_type), 
             linetype = "dashed", size = 1) +
  theme_bw() +
  labs(title = "Density Plots of Bias Types", x = "Bias Value", y = "Density") +
  scale_fill_manual(values = c("blue", "red", "green", "purple")) +  # Adjust colors as desired
  scale_color_manual(values = c("blue", "red", "green", "purple")) +  # Same color scheme for the lines
  facet_wrap(~bias_type, scales = "free")  # Separate graphs for each bias type
```

```{r}
sim_setting_1_results_MSE <- sim_setting_1_results |>
  pivot_longer(cols = c(MSE_fixed_MI, MSE_CLQI, MSE_constant, MSE_CC), 
               names_to = "MSE_type", 
               values_to = "MSE_value")

# Plot the density of each bias type
ggplot(sim_setting_1_results_MSE, aes(x = MSE_value, fill = MSE_type)) +
  geom_density(alpha = 0.25) +  # Adjust transparency with alpha
  geom_vline(data = sim_setting_1_results_MSE %>%
               group_by(MSE_type) %>%
               summarize(mean_MSE = mean(MSE_value)), 
             aes(xintercept = mean_MSE, color = MSE_type), 
             linetype = "dashed", size = 1) +
  theme_bw() +
  labs(title = "Density Plots of MSE Types", x = "MSE Value", y = "Density") +
  scale_fill_manual(values = c("blue", "red", "green", "purple")) +  # Adjust colors as desired
  scale_color_manual(values = c("blue", "red", "green", "purple")) + # Same color scheme for the lines
  facet_wrap(~MSE_type, scales = "free")  +
  xlim(0,0.5)
```

```{r}
sim_setting_1_coverage <- sim_setting_1_results |>
  summarize(cov_perc_CLQI = sum(coverage_CLQI) / nrow(sim_setting_1_results), 
            cov_perc_fixed_MI = sum(coverage_fixed_MI) / nrow(sim_setting_1_results), 
            cov_perc_constant = sum(coverage_constant) / nrow(sim_setting_1_results), 
            cov_perc_CC = sum(coverage_CC) / nrow(sim_setting_1_results))

sim_setting_1_coverage
```


*************************************************************************************************************

Other tests

```{r}
tictoc::tic() #start the timer to check

sim_setting_test_results <- repetera_full_simulation(specified_sample_size = 500, 
                                                 specified_tau = 0.01, 
                                                 specified_LD = 0.95, #95% missing data
                                                 sim_size = 1000,
                                                 b1_true = exp(log(1.1)))

tictoc::toc() # Finish the computation time
```

```{r}
#save the results and look at them!
saveRDS(sim_setting_test_results, file="./simulation_results/sim_setting_test.rds")
```

```{r}
sim_setting_test_coverage <- sim_setting_test_results |>
  summarize(cov_perc_CLQI = sum(coverage_CLQI) / nrow(sim_setting_1_results), 
            cov_perc_fixed_MI = sum(coverage_fixed_MI) / nrow(sim_setting_1_results), 
            cov_perc_constant = sum(coverage_constant) / nrow(sim_setting_1_results), 
            cov_perc_CC = sum(coverage_CC) / nrow(sim_setting_1_results))

sim_setting_test_coverage
```