
This QMD will house the simple case of CLQI, where we impute missing data from a biomarker through using one study
This method is similar to Predictive Mean Matching (PMM) where we aim to avoid implausible values and reduce bias after imputation. However, PMM has several limitations, such as only performing well under 10%-30% missing data, relying on assumptions for linear regression, and the distribution for imputation having little to moderate skew only.

```{r}
#necessary libraries
library(tidyverse)
library(ggplot2)
library(quantreg)
library(missMethods)
library(MASS)
library(purrr)
library(tictoc)
library(mice) #for PMM
```

Some important transformation functions that we will use for the CLQI algorithm

```{r}
#logit and expit functions for myself
logit <- function(prob) {
  value <- log(prob / (1 - prob))
  return(value)
}

expit <- function(x) {
  value <- 1 / (1 + exp(-x))
  return(value)
}

#now some other transformation functions
log_quant_transform <- function(value, min, max) {
  if (is.na(value)) return(NA)  # short-circuit if missing
  if (value <= min | value >= max) return(NA)
  return(log((value - min) / (max - value)))
}

inv_log_quant_transform <- function(value, min, max) {
  new_value <- (exp(value)*max + min) / (1+exp(value))
  return(new_value)
}
```

We need the theoretical mixture distribution

```{r}
#theoretical distribution values we need for transformations (chatgpt makes this quick)
get_mixture_quantile <- function(p) {
  uniroot(
    function(q) 0.6 * pchisq(q, 5) + 0.4 * pchisq(q, 8) - p,
    c(0, 1000)
  )$root
}

# Compute each quantile and assign to unique objects
q_9999 <- get_mixture_quantile(0.9999)
q_999999 <- get_mixture_quantile(0.999999)
```


The Data Generating Mechanism: just one study with a very simple mechanism defined in section 3

```{r}
data_generation <- function(sample_size, missing_prop, p_missing_zero = 0.35, p_missing_one = 0.20,
                            b_0 = logit(0.1), b_1 = log(1.1), b_2 = log(0.7)) {

  #generate my data
  B <- rbinom(sample_size, size = 1, prob = 0.4)
  V <- rnorm(sample_size, mean = 0, sd = 2.5)
  X <- rchisq(sample_size, df = 5 + 3*B) #if B = 1, X ~ chisq(8)
  Y <- plogis(b_0 + b_1*X + b_2*B) #we have some effects
  Y_bin <- rbinom(sample_size, size = 1, prob = Y)
  
  
  my_data <- data.frame(
      confounder = B,
      predictor = V,
      biomarker = X,
      missing_biomarker = X,
      missing_biomarker_MAR = X,
      outcome = Y_bin
    )

  my_data <- delete_MCAR(my_data, missing_prop, "missing_biomarker") #make missing_prop percent of data missing MCAR
  
#what about the MAR scenario?
  #get probabilities based on confounder and unif from 0 to 1 for all my datapoints
  prob <- ifelse(my_data$confounder == 1, p_missing_one, p_missing_zero)
  u <- runif(nrow(my_data))
  
  #apply MAR missingness
  my_data$missing_biomarker_MAR <- ifelse(u < prob, #if my u value is less than my probability
                                          NA, #make it missing
                                          my_data$missing_biomarker_MAR) #if not, keep the observation

#now we create the transformed variable... sapply is NOT working
  my_data$transformed_biomarker <- NA
  
  for(i in 1:nrow(my_data)) {
    if(is.na(my_data$missing_biomarker[i])) {
      my_data$transformed_biomarker[i] <- NA} 
    else {
      my_data$transformed_biomarker[i] <- log_quant_transform(my_data$missing_biomarker[i], 
                                                              min = 0, max = q_999999)}
  }
  
  return(my_data)
}
```

Some plots of generated data as a check

```{r, eval=FALSE}
created_data <- data_generation(sample_size = 2000, missing_prop = 0.5)

#FIRST CHECK: Logistic Regression 
regression_results <- glm(outcome ~ biomarker + confounder,
                          data = created_data,
                          family = "binomial")

summary(regression_results)$coefficients[2] - log(1.1) #what is the bias of the biomarker estimate?

# Convert confounder to a factor for better labeling and aesthetics
created_data$confounder <- factor(created_data$confounder, levels = c(0, 1), labels = c("Confounder = 0", "Confounder = 1"))

# Create the plot with overlaid density curves
ggplot(data = created_data, aes(x = biomarker, fill = confounder, color = confounder)) +
  geom_density(alpha = 0.5) + 
  labs(
    title = "Biomarker Distribution by Confounder",
    x = "Biomarker",
    y = "Density"
  ) +
  scale_fill_manual(values = c("skyblue", "orange")) +  # Custom colors for filling
  scale_color_manual(values = c("blue", "red"))        # Custom border colors
```

A check for MAR working:

```{r, eval=FALSE}
created_data <- data_generation(sample_size = 2000, missing_prop = 0.5)
```

# PMM: This is some simple code to demonstrate how PMM works with the `mice` package in R

```{r, eval=FALSE}
created_data_for_PMM <- data_generation(sample_size = 2000, missing_prop = 0.4) |>
  dplyr::select(confounder, missing_biomarker, outcome, predictor) #must only have the missing biomarker and the predictors

set.seed(500)
num_imp <- 10 #number of imputations

#a little test: will suppress messages in later functions
imp <- mice(created_data_for_PMM, 
            method = "pmm", 
            m = num_imp) 

#now performing multiple imputations and aggregating results with rubin rules
PMM_coefficients <- c()

for(i in 1:num_imp) {
  imputed_data <- complete(imp, action = i)
  my_reg <- glm(outcome ~ missing_biomarker + confounder,
                data = imputed_data,
                family = "binomial")
  
  PMM_coefficients[i] <- summary(my_reg)$coefficients[2]
}

mean(PMM_coefficients) - log(1.1) #we're doing pretty good 
```

# CLQI

Perform the algorithm: *this is some old code when data cannot be shared. this is still here because in the future, this may have a faster runtime*

```{r, eval=FALSE}
coefficient_data <- data.frame()

suppressWarnings({
  for(i in seq(from = 0.01, to = 0.99, by = 0.01)) {
      reg_coeff <- rq(transformed_biomarker ~ outcome + confounder + predictor, 
                      data = created_data, 
                      tau=i)
      
      #create the data frame 
      new_data <- data.frame(
        b_0 = reg_coeff$coefficients[1],
        b_outcome = reg_coeff$coefficients[2],
        b_confounder = reg_coeff$coefficients[3],
        b_predictor = reg_coeff$coefficients[4],
        quant = i)
        
      coefficient_data <- rbind(coefficient_data, new_data) #add to new iterations
    }
})

coefficient_data

#here's the function format
coefficient_generator <- function(my_data) {
  suppressWarnings({
    for(i in seq(from = 0.01, to = 0.99, by = 0.01)) {
        reg_coeff <- rq(transformed_biomarker ~ outcome + confounder + predictor, 
                        data = my_data, 
                        tau=i)
        
        #create the data frame 
        new_data <- data.frame(
          b_0 = reg_coeff$coefficients[1],
          b_outcome = reg_coeff$coefficients[2],
          b_confounder = reg_coeff$coefficients[3],
          b_predictor = reg_coeff$coefficients[4],
          quant = i)
          
        coefficient_data <- rbind(coefficient_data, new_data) #add to new iterations
      }
  })

  return(coefficient_data)
}
  
coefficient_generator(created_data) #should be the same
```

Here are the functions for CLQI when individual level data is available

```{r}
uniform_values <- function() {
  u <- runif(1, min = 1, max = 99) #aka from 0.01 to 0.99
  
  #all the values we need from the uniform
  floor_u <- floor(u)
  mod_u <- (u - floor(u))
  next_u <- ceiling(u)
  
  #now putting this into a vector
  my_u <- c(u, floor_u, mod_u, next_u)
  return(my_u)
}

imputation_algorithm <- function(my_data, row_index) {
  
  u <- runif(1, min = 0, max = 0.99) 
  
  reg_coeff <- rq(transformed_biomarker ~ outcome + confounder + predictor, 
                        data = my_data, 
                        tau = u) #straight up u value
  
  b_intercept <- reg_coeff$coefficients[1]
  b_outcome <- reg_coeff$coefficients[2]
  b_confounder <- reg_coeff$coefficients[3]
  b_predictor <- reg_coeff$coefficients[4]
  
  imputation_value_transformed <- b_intercept + (b_outcome * my_data[row_index,]$outcome) + (b_confounder * my_data[row_index,]$confounder) + (b_predictor * my_data[row_index,]$predictor)
  
  return(imputation_value_transformed)
}
```

This is the one for no sharing. Ignore for now!

```{r, eval=FALSE}
imputation_algorithm_no_sharing <- function(my_coefficients, my_data, row_index) {
  
  u_vector <- uniform_values() #get the uniform values and extract necessary information
  floor_quantile <- my_coefficients[u_vector[2], ] #floor
  modulus <- u_vector[3] #modulus
  ceiling_quantile <- my_coefficients[u_vector[4], ] #ceiling
  
  #need to calculate regression values... really messy don't look at this
  lower_quantile_value <- floor_quantile$b_0 +
    (floor_quantile$b_outcome * my_data[row_index,]$outcome) + (floor_quantile$b_confounder * my_data[row_index,]$confounder) + + (floor_quantile$b_predictor * my_data[row_index,]$predictor) 

  upper_quantile_value <- ceiling_quantile$b_0 +
    (ceiling_quantile$b_outcome * my_data[row_index,]$outcome) + (ceiling_quantile$b_confounder * my_data[row_index,]$confounder) + (ceiling_quantile$b_predictor * my_data[row_index,]$predictor)

  #now the imputation values!
  imputation_value_transformed <- ((1-modulus)*lower_quantile_value) + (modulus*upper_quantile_value)
  
  return(imputation_value_transformed)
}
```

## The following is a demonstration of CLQI

```{r, eval=FALSE}
#here are the data that we need
data_for_imp <- data_generation(sample_size = 1000, missing_prop = 0.3)

for(row_index in 1:nrow(data_for_imp)) {
  if(is.na(data_for_imp$transformed_biomarker[row_index])) {
    imputed_value <- imputation_algorithm(my_data = data_for_imp,
                                          row_index = row_index)
    
    data_for_imp$transformed_biomarker[row_index] <- imputed_value
  }
}

data_for_imp <- data_for_imp |>
  mutate(untransformed_imputed_biomarker = sapply(transformed_biomarker, inv_log_quant_transform, 
                                                  min = 0, max = q_999999))

data_for_imp #check the transformed_biomarker variable, not the missing_biomarker variable!
```

A continuation of the previous chunk to show the distributions of the imputed data with the theoretical distributions

```{r, eval=FALSE}
data_for_imp_new <- data_for_imp

data_for_imp_new$confounder <- factor(data_for_imp_new$confounder, levels = c(0, 1), labels = c("Confounder = 0", "Confounder = 1"))

# Create the plot with overlaid density curves
ggplot(data = data_for_imp_new, aes(x = biomarker, fill = confounder, color = confounder)) +
  geom_density(alpha = 0.5) + 
  labs(
    title = "Biomarker Distribution by Confounder",
    x = "Biomarker",
    y = "Density"
  ) +
  scale_fill_manual(values = c("skyblue", "orange")) +  # Custom colors for filling
  scale_color_manual(values = c("blue", "red"))        # Custom border colors


ggplot(data = data_for_imp_new, aes(x = untransformed_imputed_biomarker, fill = confounder, color = confounder)) +
  geom_density(alpha = 0.5) + 
  labs(
    title = "Imputed Biomarker Distribution by Confounder",
    x = "Biomarker",
    y = "Density"
  ) +
  scale_fill_manual(values = c("skyblue", "orange")) +  # Custom colors for filling
  scale_color_manual(values = c("blue", "red")) +       # Custom border colors
  stat_function(fun = dchisq, args = list(df = 5), aes(color = NULL), linetype = "dashed", size = 1, color = "black") +
  stat_function(fun = dchisq, args = list(df = 8), aes(color = NULL), linetype = "dotted", size = 1, color = "darkgreen")
```

Lastly, a logistic regression test

```{r, eval=FALSE}
CLQI_glm <- glm(outcome ~ untransformed_imputed_biomarker + confounder,
              data = data_for_imp,
              family = "binomial")

summary(CLQI_glm)$coefficients[2] - log(1.1)
```

# Now for *distance metrics*: 1-Wasserstein distance and KS test

```{r, eval=FALSE}
#redo data generation
set.seed(540)
data_for_imp <- data_generation(sample_size = 1000, missing_prop = 0.3)

#separate data for KS test
data_for_imp_zero <- data_for_imp |>
  filter(confounder == 0)

data_for_imp_one <- data_for_imp |>
  filter(confounder == 1)

ks.test(data_for_imp_zero$untransformed_imputed_biomarker, "pchisq", df = 5)
ks.test(data_for_imp_one$untransformed_imputed_biomarker, "pchisq", df = 8)
```

```{r, eval=FALSE}
wasserstein_1_distance <- function(variable, my_df) {
  empirical_cdf <- ecdf(variable)
  u <- seq(0, 0.9999999, length.out = 1000) #we will be working with the quantile version. Integration approximation
  
  #now get the quantiles
  empirical_quantiles <- quantile(variable, probs = u)
  theoretical_quantiles <- qchisq(u, df = my_df)
  
  return(mean(as.numeric(abs(empirical_quantiles - theoretical_quantiles))))
}

wasserstein_1_distance(data_for_imp_zero$untransformed_imputed_biomarker, my_df = 5) #from DGM
wasserstein_1_distance(data_for_imp_one$untransformed_imputed_biomarker, my_df = 8) #ditto
```

##############################################

Now for simulations: we defined a couple of functions to make verything much easier

```{r}
#rubin's rule for standard error is complicated, so just keep it in a simple function
rubin_rule_SE <- function(values_MI, SE_MI) { #both inputs are vectors
  variance_within_MI <- mean((SE_MI)^2)
  variance_between_MI <- sum((values_MI - mean(values_MI))^2) / (length(values_MI) - 1)
  total_variance <- variance_within_MI + variance_between_MI + (variance_between_MI / length(values_MI))
  
  return(sqrt(total_variance))
}
```

```{r}
coverage <- function(parameter, SE, t_star, true_val) {
  if(parameter - t_star*SE <= true_val & true_val <= parameter + t_star*SE) {
    return(1)
  } else{
    return(0)
  }
}
```

```{r}
power <- function(values_MI, SE_MI, num_MI) {
  #t stat calculation
  wald <- mean(values_MI) / rubin_rule_SE(values_MI, SE_MI)
  
  #df calculation
  variance_within_MI <- mean((SE_MI)^2)
  variance_between_MI <- sum((values_MI - mean(values_MI))^2) / (length(values_MI) - 1)
  my_frac <- variance_between_MI / (num_MI * variance_within_MI)
  df <- ((num_MI - 1) / (1 + my_frac)^2) 
  
  #our p-value
  p_value <- 2 * (1 - pt(abs(wald), df))
  
  #return 1 if we reject H0 (from DGM, we know H1 to be true)
  return(ifelse(p_value < 0.05, 1, 0))
}
```

## *A TEST for PMM* 

```{r, eval=FALSE}
testing_data <- data_generation(sample_size = 1000, missing_prop = 0.3) |>
  dplyr::select(confounder, missing_biomarker, outcome)

  num_MI_iter <- 10    
  imp <- mice(testing_data, method = "pmm", m = num_MI_iter)
  test_values_PMM <- c()
  test_SE_PMM <- c()
  
      for (j in 1:num_MI_iter) {
       imputed_data <- complete(imp, action = j)
        my_reg <- glm(outcome ~ missing_biomarker + confounder,
                      data = imputed_data,
                      family = "binomial")
        
        test_values_PMM[j] <- summary(my_reg)$coefficients[2]
        test_SE_PMM[j] <- summary(my_reg)$coefficients[2, 2]
      }
      
  #estimate
  test_estimate_values_PMM <- mean(test_values_PMM)
      
    #now FOR COVERAGE
    test_total_SE_PMM <- rubin_rule_SE(test_values_PMM, test_SE_PMM)
      
    t_star <- qt(0.975, df = 1000 - 1)
    coverage_PMM <- coverage(parameter = mean(test_values_PMM),
                             SE = test_total_SE_PMM,
                             t_star = t_star,
                             true_val = log(1.1))
    coverage_PMM
    
    #now for power...
    power_PMM <- power(test_values_PMM, test_SE_PMM, MI_iter)
    power_PMM
      
    #something seems off, so manual calculation... this will get rejected.
    wald_PMM <- mean(test_values_PMM) / rubin_rule_SE(test_values_PMM, test_SE_PMM)
    wald_PMM #wow that's low...
```

### *A FUNCTION FOR PMM*

```{r}
PMM <- function(my_data, num_MI_iter) {
  suppressMessages({
  suppressWarnings({
  capture.output({
        
      imp <- mice(my_data, method = "pmm", m = num_MI_iter)
        
      values_PMM <- c()
      SE_PMM <- c()
        
      # the for loop to extract values and SE
      for (j in 1:num_MI_iter) {
        imputed_data <- complete(imp, action = j)
        my_reg <- glm(outcome ~ missing_biomarker + confounder,
                      data = imputed_data,
                      family = "binomial")
          
        # store these values
        values_PMM[j] <- summary(my_reg)$coefficients["missing_biomarker", "Estimate"]
        SE_PMM[j] <- summary(my_reg)$coefficients["missing_biomarker", "Std. Error"]
      }
        
      results_PMM <- list(values_PMM, SE_PMM)
        
      return(results_PMM)
        
  }) # end capture.output
  }) # end suppressWarnings
  }) # end suppressMessages
}

testing_data <- data_generation(sample_size = 1000, missing_prop = 0.3) |>
  dplyr::select(confounder, missing_biomarker, outcome)

a <- PMM(testing_data, num_MI_iter = 10)
as.vector(a[[1]])
```

## *A TEST FOR CLQI*

```{r, eval=FALSE}
values_CLQI <- c()
SE_CLQI <- c()
MI_iter <- 10 
data_for_imp_fresh <- data_generation(sample_size = 1000, missing_prop = 0.3)

for(imp in 1:MI_iter) {
  
  data_for_imp <- data_for_imp_fresh #resets any imputation that happened
  
  for(row_index in 1:nrow(data_for_imp)) {
    if(is.na(data_for_imp$transformed_biomarker[row_index])) {
      imputed_value <- imputation_algorithm(my_data = data_for_imp,
                                            row_index = row_index)
      
      data_for_imp$transformed_biomarker[row_index] <- imputed_value
    }
  }
  
  data_for_imp <- data_for_imp |>
  mutate(untransformed_imputed_biomarker = sapply(transformed_biomarker, inv_log_quant_transform, 
                                                  min = 0, max = q_999999))

  my_glm <- glm(outcome ~ untransformed_imputed_biomarker + confounder,
              data = data_for_imp,
              family = "binomial")

  values_CLQI[imp] <- summary(my_glm)$coefficients[2]
  SE_CLQI[imp] <- summary(my_glm)$coefficients[2,2]
}

      estimated_CLQI <- mean(values_CLQI)
      
      #now FOR COVERAGE
      test_total_SE_PMM <- rubin_rule_SE(values_CLQI, SE_CLQI)
      
      t_star <- qt(0.975, df = 1000 - 1)
      coverage_PMM <- coverage(parameter = mean(values_CLQI),
                                SE = test_total_SE_PMM,
                                t_star = t_star,
                                true_val = log(1.1))

      #power
      power_CLQI <- power(values_CLQI, SE_CLQI, MI_iter)
      
      wald_CLQI <- mean(values_CLQI) / rubin_rule_SE(values_CLQI, SE_CLQI)
      wald_CLQI  

values_CLQI
mean(values_CLQI) - log(1.1) #bias...
```

### *A FUNCTION FOR CLQI*

```{r}
CLQI <- function(my_data, num_MI_iter) {
  
  values_CLQI <- c()
  SE_CLQI <- c()
  
  for(imp in 1:num_MI_iter) {
    my_data_iteration <- my_data #resets any imputation that happened
    
    for(row_index in 1:nrow(my_data_iteration)) {
      if(is.na(my_data_iteration$transformed_biomarker[row_index])) {
        imputed_value <- imputation_algorithm(my_data = my_data_iteration,
                                              row_index = row_index)
        
        my_data_iteration$transformed_biomarker[row_index] <- imputed_value
      }
    }
  
  #after running the algorithm, we untransform, perform log reg, save coefficients, rinse and repeat
  my_data_iteration <- my_data_iteration |>
  mutate(untransformed_imputed_biomarker = sapply(transformed_biomarker, inv_log_quant_transform, 
                                                  min = 0, max = q_999999))

  my_glm <- glm(outcome ~ untransformed_imputed_biomarker + confounder,
              data = my_data_iteration,
              family = "binomial")

  values_CLQI[imp] <- summary(my_glm)$coefficients[2]
  SE_CLQI[imp] <- summary(my_glm)$coefficients[2,2]
  } 
  
  CLQI_results <- list(values_CLQI, SE_CLQI)
  return(CLQI_results)
}

testing_data <- data_generation(sample_size = 1000, missing_prop = 0.3)

b <- CLQI(testing_data, num_MI_iter = 10)
b[1]
```

```{r}
complete_case <- function(my_data) {
  my_glm <- glm(outcome ~ missing_biomarker + confounder,
              data = my_data,
              family = "binomial")
  
  value_CC <- summary(my_glm)$coefficients[2]
  SE_CC <- summary(my_glm)$coefficients[2,2]
  pval_CC <- summary(my_glm)$coefficients["missing_biomarker", "Pr(>|z|)"]
  
  return(c(value_CC, SE_CC, pval_CC))
}

testing_data <- data_generation(sample_size = 1000, missing_prop = 0.3)

c <- complete_case(testing_data)
c[1] #the estimate
```



# MY INITIAL SIMULATION STUDY

```{r}
my_iter_count <- 0

#this is to make reading the code much easier
set.seed(500)
my_sample <- 1000 #sample size for each dataset
num_sim <- 1000 #number of simulations
MI_iter <- 10
prop_data_missing <- 0.3 #proportion of data missing

#here are some vectors we have to define... this is still messy since it's not in a full function
estimate_values_PMM <- c()
SE_values_PMM <- c()
coverage_PMM <- c()
power_PMM <- c()

estimate_values_CLQI <- c()
SE_values_CLQI <- c()
coverage_CLQI <- c()
power_CLQI <- c()

estimate_values_CC <- c()
SE_values_CC <- c()
coverage_CC <- c()
power_CC <- c()

#now for our loop
tictoc::tic() #check runtime for entire simulation
for(i in 1:num_sim) { #for each simulation
  data_for_imp <- data_generation(sample_size = my_sample, 
                                  missing_prop = prop_data_missing) #generate my data
  
  #get values for estimate and SE from PMM
  data_for_imp_PMM <- data_for_imp  |>
    dplyr::select(confounder, missing_biomarker, outcome)
  
  PMM_results <- PMM(data_for_imp_PMM, num_MI_iter = MI_iter) #1 is estimates, 2 is SE
    values_PMM <- as.vector(PMM_results[[1]])
    SE_PMM <- as.vector(PMM_results[[2]])
  
  #perform calculations to get estimate, bias, relative bias, RMSE, coverage, power for PMM
      estimate_values_PMM[i] <- mean(values_PMM)
      SE_values_PMM[i] <- rubin_rule_SE(values_PMM, SE_PMM)
      
      t_star <- qt(0.975, df = my_sample - 1)
      coverage_PMM[i] <- coverage(parameter = estimate_values_PMM[i],
                                  SE = SE_values_PMM[i],
                                  t_star = t_star,
                                  true_val = log(1.1))
      
      power_PMM[i] <- power(values_PMM, SE_PMM, MI_iter)
####
  #get values for estimate and SE from CLQI
  CLQI_results <- CLQI(data_for_imp, num_MI_iter = MI_iter) #1 is estimates, 2 is SE
    values_CLQI <- as.vector(CLQI_results[[1]])
    SE_CLQI <- as.vector(CLQI_results[[2]])

  #perform calculations to get estimate, bias, relative bias, RMSE, coverage, power for CLQI
      estimate_values_CLQI[i] <- mean(values_CLQI)
      SE_values_CLQI[i] <- rubin_rule_SE(values_CLQI, SE_CLQI)
      
      t_star <- qt(0.975, df = my_sample - 1)
      coverage_CLQI[i] <- coverage(parameter = estimate_values_CLQI[i],
                                   SE = SE_values_CLQI[i],
                                   t_star = t_star,
                                   true_val = log(1.1))
      
      power_CLQI[i] <- power(values_CLQI, SE_CLQI, MI_iter)
#### 
  #perform complete case analysis
  complete_case_results <- complete_case(data_for_imp)
    
  #perform calculations to get estimate, bias, relative bias, RMSE, coverage, power for CC
    estimate_values_CC[i] <- complete_case_results[1]
    SE_values_CC[i] <- complete_case_results[1]
    
    t_star <- qt(0.975, df = my_sample - 1)
    coverage_CC[i] <- coverage(parameter = estimate_values_CC[i],
                               SE = SE_values_CC[i],
                               t_star = t_star,
                               true_val = log(1.1))
    
    power_CC[i] <- ifelse(as.numeric(complete_case_results[3]) < 0.05, 1, 0) #if p-val < 0.05, it's 1. Else, it's 0.
    
  #we will be repeating this 1000 times
  my_iter_count <- my_iter_count + 1
  print(my_iter_count)
}
tictoc::toc()

#create bias rows
bias_values_PMM <- estimate_values_PMM - log(1.1)
bias_values_CLQI <- estimate_values_CLQI - log(1.1)
bias_values_CC <- estimate_values_CC - log(1.1)

#and at the end, combine all these vectors into a single dataframe
my_simulation_results_q_999999 <- data.frame(
  estimate_values_PMM = estimate_values_PMM,
  bias_values_PMM = bias_values_PMM,
  SE_values_PMM = SE_values_PMM,
  RMSE_values_PMM = sqrt(bias_values_PMM^2 + SE_values_PMM^2),
  coverage_PMM = coverage_PMM,
  power_PMM = power_PMM, #done
  estimate_values_CLQI = estimate_values_CLQI,
  bias_values_CLQI = bias_values_CLQI,
  SE_values_CLQI = SE_values_CLQI,
  RMSE_values_CLQI = sqrt(bias_values_CLQI^2 + SE_values_CLQI^2),
  coverage_CLQI = coverage_CLQI,
  power_CLQI = power_CLQI, #done
  estimate_values_CC= estimate_values_CC,
  bias_values_CC= bias_values_CC,
  SE_values_CC = SE_values_CC,
  RMSE_values_CC = sqrt(bias_values_CC^2 + SE_values_CC^2),
  coverage_CC = coverage_CC,
  power_CC = power_CC
)

my_simulation_results_q_999999
```

```{r}
#quick bias checks 
(mean(my_simulation_results_q_999999$estimate_values_CLQI) - log(1.1)) / log(1.1) * 100
(mean(my_simulation_results_q_999999$estimate_values_PMM) - log(1.1)) / log(1.1) * 100
(mean(my_simulation_results_q_999999$estimate_values_CC) - log(1.1)) / log(1.1) * 100

#now for RMSE
mean(my_simulation_results_q_999999$RMSE_values_CLQI)
mean(my_simulation_results_q_999999$RMSE_values_PMM)
mean(my_simulation_results_q_999999$RMSE_values_CC)

#now for coverage
mean(my_simulation_results_q_999999$coverage_CLQI)
mean(my_simulation_results_q_999999$coverage_PMM)
mean(my_simulation_results_q_999999$coverage_CC)

#now for power
mean(my_simulation_results_q_999999$power_CLQI)
mean(my_simulation_results_q_999999$power_PMM)
mean(my_simulation_results_q_999999$power_CC)

#save this!
saveRDS(my_simulation_results_q_999999, file="./simulations_setting4.rds")
```



# A SECOND ONE WITH 60 PERCENT

# MY INITIAL SIMULATION STUDY

```{r}
my_iter_count <- 0

#this is to make reading the code much easier
set.seed(500)
my_sample <- 1000 #sample size for each dataset
num_sim <- 1000 #number of simulations
MI_iter <- 25
prop_data_missing <- 0.6 #proportion of data missing

#here are some vectors we have to define... this is still messy since it's not in a full function
estimate_values_PMM <- c()
SE_values_PMM <- c()
coverage_PMM <- c()
power_PMM <- c()

estimate_values_CLQI <- c()
SE_values_CLQI <- c()
coverage_CLQI <- c()
power_CLQI <- c()

estimate_values_CC <- c()
SE_values_CC <- c()
coverage_CC <- c()
power_CC <- c()

#now for our loop
tictoc::tic() #check runtime for entire simulation
for(i in 1:num_sim) { #for each simulation
  data_for_imp <- data_generation(sample_size = my_sample, 
                                  missing_prop = prop_data_missing) #generate my data
  
  #get values for estimate and SE from PMM
  data_for_imp_PMM <- data_for_imp  |>
    dplyr::select(confounder, missing_biomarker, outcome)
  
  PMM_results <- PMM(data_for_imp_PMM, num_MI_iter = MI_iter) #1 is estimates, 2 is SE
    values_PMM <- as.vector(PMM_results[[1]])
    SE_PMM <- as.vector(PMM_results[[2]])
  
  #perform calculations to get estimate, bias, relative bias, RMSE, coverage, power for PMM
      estimate_values_PMM[i] <- mean(values_PMM)
      SE_values_PMM[i] <- rubin_rule_SE(values_PMM, SE_PMM)
      
      t_star <- qt(0.975, df = my_sample - 1)
      coverage_PMM[i] <- coverage(parameter = estimate_values_PMM[i],
                                  SE = SE_values_PMM[i],
                                  t_star = t_star,
                                  true_val = log(1.1))
      
      power_PMM[i] <- power(values_PMM, SE_PMM, MI_iter)
####
  #get values for estimate and SE from CLQI
  CLQI_results <- CLQI(data_for_imp, num_MI_iter = MI_iter) #1 is estimates, 2 is SE
    values_CLQI <- as.vector(CLQI_results[[1]])
    SE_CLQI <- as.vector(CLQI_results[[2]])

  #perform calculations to get estimate, bias, relative bias, RMSE, coverage, power for CLQI
      estimate_values_CLQI[i] <- mean(values_CLQI)
      SE_values_CLQI[i] <- rubin_rule_SE(values_CLQI, SE_CLQI)
      
      t_star <- qt(0.975, df = my_sample - 1)
      coverage_CLQI[i] <- coverage(parameter = estimate_values_CLQI[i],
                                   SE = SE_values_CLQI[i],
                                   t_star = t_star,
                                   true_val = log(1.1))
      
      power_CLQI[i] <- power(values_CLQI, SE_CLQI, MI_iter)
#### 
  #perform complete case analysis
  complete_case_results <- complete_case(data_for_imp)
    
  #perform calculations to get estimate, bias, relative bias, RMSE, coverage, power for CC
    estimate_values_CC[i] <- complete_case_results[1]
    SE_values_CC[i] <- complete_case_results[1]
    
    t_star <- qt(0.975, df = my_sample - 1)
    coverage_CC[i] <- coverage(parameter = estimate_values_CC[i],
                               SE = SE_values_CC[i],
                               t_star = t_star,
                               true_val = log(1.1))
    
    power_CC[i] <- ifelse(as.numeric(complete_case_results[3]) < 0.05, 1, 0) #if p-val < 0.05, it's 1. Else, it's 0.
    
  #we will be repeating this 1000 times
  my_iter_count <- my_iter_count + 1
  print(my_iter_count)
}
tictoc::toc()

#create bias rows
bias_values_PMM <- estimate_values_PMM - log(1.1)
bias_values_CLQI <- estimate_values_CLQI - log(1.1)
bias_values_CC <- estimate_values_CC - log(1.1)

#and at the end, combine all these vectors into a single dataframe
my_simulation_results_60 <- data.frame(
  estimate_values_PMM = estimate_values_PMM,
  bias_values_PMM = bias_values_PMM,
  SE_values_PMM = SE_values_PMM,
  RMSE_values_PMM = sqrt(bias_values_PMM^2 + SE_values_PMM^2),
  coverage_PMM = coverage_PMM,
  power_PMM = power_PMM, #done
  estimate_values_CLQI = estimate_values_CLQI,
  bias_values_CLQI = bias_values_CLQI,
  SE_values_CLQI = SE_values_CLQI,
  RMSE_values_CLQI = sqrt(bias_values_CLQI^2 + SE_values_CLQI^2),
  coverage_CLQI = coverage_CLQI,
  power_CLQI = power_CLQI, #done
  estimate_values_CC= estimate_values_CC,
  bias_values_CC= bias_values_CC,
  SE_values_CC = SE_values_CC,
  RMSE_values_CC = sqrt(bias_values_CC^2 + SE_values_CC^2),
  coverage_CC = coverage_CC,
  power_CC = power_CC
)

my_simulation_results_60
```

```{r}
#quick bias checks 
(mean(my_simulation_results_60$estimate_values_CLQI) - log(1.1)) / log(1.1) * 100
(mean(my_simulation_results_60$estimate_values_PMM) - log(1.1)) / log(1.1) * 100
(mean(my_simulation_results_60$estimate_values_CC) - log(1.1)) / log(1.1) * 100

#now for RMSE
mean(my_simulation_results_60$RMSE_values_CLQI)
mean(my_simulation_results_60$RMSE_values_PMM)
mean(my_simulation_results_60$RMSE_values_CC)

#now for coverage
mean(my_simulation_results_60$coverage_CLQI)
mean(my_simulation_results_60$coverage_PMM)
mean(my_simulation_results_60$coverage_CC)

#now for power
mean(my_simulation_results_60$power_CLQI)
mean(my_simulation_results_60$power_PMM)
mean(my_simulation_results_60$power_CC)

#save this!
saveRDS(my_simulation_results_60, file="./simulations_setting_60_perc.rds")
```









Now a check!

```{r}
simulation_setting_30_perc <- readRDS(file="./sim_results/simulations_setting4.rds")

sim_setting_long <- simulation_setting_30_perc |>
  dplyr::select(estimate_values_CLQI, estimate_values_PMM) |>
  rename(CLQI = estimate_values_CLQI, PMM = estimate_values_PMM) |> #rename so i don't have to do weird legend things
  pivot_longer(cols = everything(),
               names_to = "method",
               values_to = "value")
#my ggplot!
ggplot(sim_setting_long, aes(x = value, color = method, fill = method)) +
  geom_density(alpha = 0.2) +
  geom_vline(xintercept = log(1.1), linetype = "dashed", color = "black") +
  labs(title = "Density Plot of Estimates", 
       x = "Estimate Value", 
       y = "Density") + 
  theme(text = element_text(size = 13))
```

#################################################################################

```{r}
# Plot histogram of your biomarker data
hist(created_data$biomarker, probability = TRUE, breaks = 100,
     col = "lightgray", border = "white",
     main = "Empirical Biomarker vs. Theoretical Mixture",
     xlab = "Biomarker")

# Generate a sequence of x-values covering the range of your data
x_vals <- seq(min(created_data$biomarker), 
              quantile(created_data$biomarker, 0.99), 
              length.out = 1000)

# Calculate theoretical mixture density
mixture_density <- 0.6 * dchisq(x_vals, df = 5) + 0.4 * dchisq(x_vals, df = 8)

# Overlay the theoretical density curve
lines(x_vals, mixture_density, col = "red", lwd = 2)

# Add a legend
legend("topright", legend = "Theoretical Mixture: 0.6 * χ²(5) + 0.4 * χ²(8)",
       col = "red", lwd = 2, bty = "n")
```

